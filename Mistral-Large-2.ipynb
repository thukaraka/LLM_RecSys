{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:25:46.013115Z",
     "start_time": "2025-08-29T13:25:45.897072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  interaction_count                          title\n",
      "0        50                583               Star Wars (1977)\n",
      "1       258                509                 Contact (1997)\n",
      "2       100                508                   Fargo (1996)\n",
      "3       181                507      Return of the Jedi (1983)\n",
      "4       294                485               Liar Liar (1997)\n",
      "5       286                481    English Patient, The (1996)\n",
      "6       288                478                  Scream (1996)\n",
      "7         1                452               Toy Story (1995)\n",
      "8       300                431           Air Force One (1997)\n",
      "9       121                429  Independence Day (ID4) (1996)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_movies = pd.read_csv('final_movies.csv')\n",
    "df_genres = pd.read_csv('movies_100k_genres.csv')\n",
    "col_names_for_user_ratings = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "col_names_for_users = ['user_id' , 'age' , 'gender' , 'occupation' ,'zip code']\n",
    "col_names_for_user_ratings = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "df_user_ratings = pd.read_csv(\n",
    "    'ml-100k/u.data',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=col_names_for_user_ratings,\n",
    "    encoding='latin-1'\n",
    ")\n",
    "\n",
    "# Step 1: Count interactions\n",
    "movie_interactions = (\n",
    "    df_user_ratings\n",
    "    .groupby('movie_id')\n",
    "    .size()\n",
    "    .reset_index(name='interaction_count')\n",
    "    .sort_values(by='interaction_count', ascending=False)\n",
    ")\n",
    "\n",
    "# Step 2: Attach movie titles\n",
    "movie_with_titles = movie_interactions.merge(df_movies[['movie_id', 'title']], on='movie_id', how='left')\n",
    "\n",
    "# Step 3: Show results\n",
    "print(movie_with_titles.head(10))\n",
    "\n",
    "\n",
    "df_users = pd.read_csv(\n",
    "    'ml-100k/u.user',\n",
    "    sep='|',\n",
    "    header=None,\n",
    "    names=col_names_for_users,\n",
    "    encoding='latin-1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7cc22a4f9c0f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:25:50.767832Z",
     "start_time": "2025-08-29T13:25:50.748757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>...</th>\n",
       "      <th>tmdb_popularity_score</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_companies_origin_country</th>\n",
       "      <th>runtime</th>\n",
       "      <th>revenue</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>directors_info</th>\n",
       "      <th>popular</th>\n",
       "      <th>unique_producers</th>\n",
       "      <th>popular_producer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>8.3</td>\n",
       "      <td>False</td>\n",
       "      <td>30000000</td>\n",
       "      <td>US</td>\n",
       "      <td>18849</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1155</td>\n",
       "      <td>Pixar</td>\n",
       "      <td>US</td>\n",
       "      <td>81</td>\n",
       "      <td>394436586.0</td>\n",
       "      <td>English</td>\n",
       "      <td>[['John Lasseter', '2.0842', 'Male']]</td>\n",
       "      <td>1</td>\n",
       "      <td>['Pixar']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>113189</td>\n",
       "      <td>710</td>\n",
       "      <td>7.2</td>\n",
       "      <td>False</td>\n",
       "      <td>60000000</td>\n",
       "      <td>GB</td>\n",
       "      <td>4012</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4216</td>\n",
       "      <td>EON Productions</td>\n",
       "      <td>GB</td>\n",
       "      <td>130</td>\n",
       "      <td>352194034.0</td>\n",
       "      <td>English,Pусский,Español</td>\n",
       "      <td>[['Martin Campbell', '0.9017', 'Male']]</td>\n",
       "      <td>1</td>\n",
       "      <td>['EON Productions']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>113101</td>\n",
       "      <td>5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>4000000</td>\n",
       "      <td>US</td>\n",
       "      <td>2694</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4017</td>\n",
       "      <td>Miramax,A Band Apart</td>\n",
       "      <td>US,US</td>\n",
       "      <td>98</td>\n",
       "      <td>4257354.0</td>\n",
       "      <td>English</td>\n",
       "      <td>[['Allison Anders', '0.3886', 'Female'], ['Ale...</td>\n",
       "      <td>0</td>\n",
       "      <td>['A Band Apart', 'Miramax']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>113161</td>\n",
       "      <td>8012</td>\n",
       "      <td>6.9</td>\n",
       "      <td>False</td>\n",
       "      <td>30250000</td>\n",
       "      <td>US</td>\n",
       "      <td>1095</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0703</td>\n",
       "      <td>Metro-Goldwyn-Mayer,Jersey Films</td>\n",
       "      <td>US,US</td>\n",
       "      <td>105</td>\n",
       "      <td>115101622.0</td>\n",
       "      <td>English</td>\n",
       "      <td>[['Barry Sonnenfeld', '0.7884', 'Male']]</td>\n",
       "      <td>0</td>\n",
       "      <td>['Jersey Films', 'Metro-Goldwyn-Mayer']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>112722</td>\n",
       "      <td>1710</td>\n",
       "      <td>6.6</td>\n",
       "      <td>False</td>\n",
       "      <td>20000000</td>\n",
       "      <td>US</td>\n",
       "      <td>1014</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3406</td>\n",
       "      <td>New Regency Pictures,Regency Enterprises,Warne...</td>\n",
       "      <td>US,US,US</td>\n",
       "      <td>124</td>\n",
       "      <td>32000000.0</td>\n",
       "      <td>English,Deutsch,Italiano</td>\n",
       "      <td>[['Jon Amiel', '0.4666', 'Male']]</td>\n",
       "      <td>0</td>\n",
       "      <td>['Warner Bros. Pictures', 'Regency Enterprises...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>110</td>\n",
       "      <td>Operation Dumbo Drop (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>114048</td>\n",
       "      <td>27281</td>\n",
       "      <td>5.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>181</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3180</td>\n",
       "      <td>Interscope Communications,Walt Disney Pictures...</td>\n",
       "      <td>US,US,US</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>English,Español,Tiếng Việt</td>\n",
       "      <td>[['Simon Wincer', '0.5484', 'Male']]</td>\n",
       "      <td>0</td>\n",
       "      <td>['Interscope Communications', 'Walt Disney Pic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>111</td>\n",
       "      <td>Truth About Cats &amp; Dogs, The (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>117979</td>\n",
       "      <td>8866</td>\n",
       "      <td>6.3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>Noon Attack Pictures,20th Century Fox</td>\n",
       "      <td>US,US</td>\n",
       "      <td>93</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>English</td>\n",
       "      <td>[['Michael Lehmann', '0.8774', 'Male']]</td>\n",
       "      <td>0</td>\n",
       "      <td>['Noon Attack Pictures', '20th Century Fox']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>112</td>\n",
       "      <td>Flipper (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>116322</td>\n",
       "      <td>36355</td>\n",
       "      <td>5.3</td>\n",
       "      <td>False</td>\n",
       "      <td>25530000</td>\n",
       "      <td>US</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>The Bubble Factory,Universal Pictures,American...</td>\n",
       "      <td>US,US,</td>\n",
       "      <td>95</td>\n",
       "      <td>20080020.0</td>\n",
       "      <td>Français,English</td>\n",
       "      <td>[['Alan Shapiro', '0.2599', 'Male']]</td>\n",
       "      <td>0</td>\n",
       "      <td>['The Bubble Factory', 'American Films', 'Univ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>113</td>\n",
       "      <td>Horseman on the Roof, The (Hussard sur le toit...</td>\n",
       "      <td>1996</td>\n",
       "      <td>113362</td>\n",
       "      <td>11876</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35000000</td>\n",
       "      <td>FR</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>Hachette Première,France 2 Cinéma,Canal+</td>\n",
       "      <td>FR,FR,FR</td>\n",
       "      <td>135</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>Français,Italiano</td>\n",
       "      <td>[['Jean-Paul Rappeneau', '0.2048', 'Male']]</td>\n",
       "      <td>0</td>\n",
       "      <td>['France 2 Cinéma', 'Hachette Première', 'Cana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>114</td>\n",
       "      <td>Wallace &amp; Gromit: The Best of Aardman Animatio...</td>\n",
       "      <td>1996</td>\n",
       "      <td>118114</td>\n",
       "      <td>503475</td>\n",
       "      <td>6.8</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>US,GB</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>Northern Arts Entertainment,Aardman</td>\n",
       "      <td>,GB</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>English</td>\n",
       "      <td>[['Nick Park', '0.8329', 'Male'], ['Peter Lord...</td>\n",
       "      <td>0</td>\n",
       "      <td>['Aardman', 'Northern Arts Entertainment']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                                              title  release_year  \\\n",
       "0          1                                   Toy Story (1995)          1995   \n",
       "1          2                                   GoldenEye (1995)          1995   \n",
       "2          3                                  Four Rooms (1995)          1995   \n",
       "3          4                                  Get Shorty (1995)          1995   \n",
       "4          5                                     Copycat (1995)          1995   \n",
       "..       ...                                                ...           ...   \n",
       "95       110                        Operation Dumbo Drop (1995)          1995   \n",
       "96       111                Truth About Cats & Dogs, The (1996)          1996   \n",
       "97       112                                     Flipper (1996)          1996   \n",
       "98       113  Horseman on the Roof, The (Hussard sur le toit...          1996   \n",
       "99       114  Wallace & Gromit: The Best of Aardman Animatio...          1996   \n",
       "\n",
       "    imdbId  tmdbId  imdb_rating  adult    budget origin_country  vote_count  \\\n",
       "0   114709     862          8.3  False  30000000             US       18849   \n",
       "1   113189     710          7.2  False  60000000             GB        4012   \n",
       "2   113101       5          6.7  False   4000000             US        2694   \n",
       "3   113161    8012          6.9  False  30250000             US        1095   \n",
       "4   112722    1710          6.6  False  20000000             US        1014   \n",
       "..     ...     ...          ...    ...       ...            ...         ...   \n",
       "95  114048   27281          5.2  False         0             US         181   \n",
       "96  117979    8866          6.3  False         0             US         324   \n",
       "97  116322   36355          5.3  False  25530000             US         321   \n",
       "98  113362   11876          7.0  False  35000000             FR         142   \n",
       "99  118114  503475          6.8  False         0          US,GB           5   \n",
       "\n",
       "    ...  tmdb_popularity_score  \\\n",
       "0   ...                23.1155   \n",
       "1   ...                 6.4216   \n",
       "2   ...                 3.4017   \n",
       "3   ...                 4.0703   \n",
       "4   ...                 4.3406   \n",
       "..  ...                    ...   \n",
       "95  ...                 1.3180   \n",
       "96  ...                 0.8527   \n",
       "97  ...                 1.5222   \n",
       "98  ...                 0.8914   \n",
       "99  ...                 0.6262   \n",
       "\n",
       "                                 production_companies  \\\n",
       "0                                               Pixar   \n",
       "1                                     EON Productions   \n",
       "2                                Miramax,A Band Apart   \n",
       "3                    Metro-Goldwyn-Mayer,Jersey Films   \n",
       "4   New Regency Pictures,Regency Enterprises,Warne...   \n",
       "..                                                ...   \n",
       "95  Interscope Communications,Walt Disney Pictures...   \n",
       "96              Noon Attack Pictures,20th Century Fox   \n",
       "97  The Bubble Factory,Universal Pictures,American...   \n",
       "98           Hachette Première,France 2 Cinéma,Canal+   \n",
       "99                Northern Arts Entertainment,Aardman   \n",
       "\n",
       "   production_companies_origin_country  runtime      revenue  \\\n",
       "0                                   US       81  394436586.0   \n",
       "1                                   GB      130  352194034.0   \n",
       "2                                US,US       98    4257354.0   \n",
       "3                                US,US      105  115101622.0   \n",
       "4                             US,US,US      124   32000000.0   \n",
       "..                                 ...      ...          ...   \n",
       "95                            US,US,US      107          0.0   \n",
       "96                               US,US       93       3407.0   \n",
       "97                              US,US,       95   20080020.0   \n",
       "98                            FR,FR,FR      135   15000000.0   \n",
       "99                                 ,GB       75          0.0   \n",
       "\n",
       "              spoken_languages  \\\n",
       "0                      English   \n",
       "1      English,Pусский,Español   \n",
       "2                      English   \n",
       "3                      English   \n",
       "4     English,Deutsch,Italiano   \n",
       "..                         ...   \n",
       "95  English,Español,Tiếng Việt   \n",
       "96                     English   \n",
       "97            Français,English   \n",
       "98           Français,Italiano   \n",
       "99                     English   \n",
       "\n",
       "                                       directors_info  popular  \\\n",
       "0               [['John Lasseter', '2.0842', 'Male']]        1   \n",
       "1             [['Martin Campbell', '0.9017', 'Male']]        1   \n",
       "2   [['Allison Anders', '0.3886', 'Female'], ['Ale...        0   \n",
       "3            [['Barry Sonnenfeld', '0.7884', 'Male']]        0   \n",
       "4                   [['Jon Amiel', '0.4666', 'Male']]        0   \n",
       "..                                                ...      ...   \n",
       "95               [['Simon Wincer', '0.5484', 'Male']]        0   \n",
       "96            [['Michael Lehmann', '0.8774', 'Male']]        0   \n",
       "97               [['Alan Shapiro', '0.2599', 'Male']]        0   \n",
       "98        [['Jean-Paul Rappeneau', '0.2048', 'Male']]        0   \n",
       "99  [['Nick Park', '0.8329', 'Male'], ['Peter Lord...        0   \n",
       "\n",
       "                                     unique_producers popular_producer  \n",
       "0                                           ['Pixar']                0  \n",
       "1                                 ['EON Productions']                0  \n",
       "2                         ['A Band Apart', 'Miramax']                1  \n",
       "3             ['Jersey Films', 'Metro-Goldwyn-Mayer']                1  \n",
       "4   ['Warner Bros. Pictures', 'Regency Enterprises...                1  \n",
       "..                                                ...              ...  \n",
       "95  ['Interscope Communications', 'Walt Disney Pic...                1  \n",
       "96       ['Noon Attack Pictures', '20th Century Fox']                1  \n",
       "97  ['The Bubble Factory', 'American Films', 'Univ...                1  \n",
       "98  ['France 2 Cinéma', 'Hachette Première', 'Cana...                0  \n",
       "99         ['Aardman', 'Northern Arts Entertainment']                0  \n",
       "\n",
       "[100 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb6f44d91c32d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:25:53.584124Z",
     "start_time": "2025-08-29T13:25:53.571286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n"
     ]
    }
   ],
   "source": [
    "unique_user_count = df_user_ratings['user_id'].nunique()\n",
    "print(unique_user_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb850d5a04c1416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:25:55.521450Z",
     "start_time": "2025-08-29T13:25:55.458447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, 364 users remain.\n",
      "Train set: 59469 rows\n",
      "Test set:  15053 rows\n",
      "Minimum number of interactions among kept users: 100\n",
      "Number of users with <= 100 interactions: 579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_user_ratings[\"date\"] = pd.to_datetime(df_user_ratings[\"timestamp\"], unit='s')\n",
    "\n",
    "# Count interactions per user\n",
    "interaction_counts = df_user_ratings.groupby('user_id').size()\n",
    "\n",
    "# Filter users with more than 60 interactions (strictly > 100)\n",
    "valid_users = interaction_counts[interaction_counts >= 100].index\n",
    "\n",
    "# Apply the filter\n",
    "df_filtered_user_ratings = df_user_ratings[df_user_ratings['user_id'].isin(valid_users)].copy()\n",
    "\n",
    "# Sort interactions chronologically per user\n",
    "df_filtered_user_ratings.sort_values(['user_id', 'date'], inplace=True)\n",
    "\n",
    "# Split each user's history: 80% train, 20% test\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for uid, user_df in df_filtered_user_ratings.groupby('user_id', sort=False):\n",
    "    n = len(user_df)\n",
    "    split_pt = int(n * 0.8)\n",
    "    train_list.append(user_df.iloc[:split_pt])\n",
    "    test_list.append(user_df.iloc[split_pt:])\n",
    "\n",
    "# Combine all user splits\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "# Output some stats\n",
    "print(f\"After filtering, {len(valid_users)} users remain.\")\n",
    "print(f\"Train set: {len(train_df)} rows\")\n",
    "print(f\"Test set:  {len(test_df)} rows\")\n",
    "\n",
    "print(f\"Minimum number of interactions among kept users: {interaction_counts[valid_users].min()}\")\n",
    "print(f\"Number of users with <= 100 interactions: {(interaction_counts < 100).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0992209da14cfe9",
   "metadata": {},
   "source": [
    "pick random user for few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb058916030c6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:26:01.581316Z",
     "start_time": "2025-08-29T13:26:01.575712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked users: [1, 92, 433]\n",
      "Remaining valid users: [5, 6, 7, 10, 11, 13, 15, 16, 18, 21, 22, 23, 26, 38, 42, 43, 44, 49, 56, 57, 58, 59, 60, 62, 64, 70, 72, 82, 83, 85, 87, 90, 94, 95, 99, 102, 104, 109, 110, 116, 119, 125, 128, 130, 141, 144, 145, 151, 152, 158, 159, 160, 174, 177, 178, 181, 184, 188, 189, 193, 194, 197, 198, 200, 201, 207, 210, 213, 214, 216, 221, 222, 223, 224, 230, 233, 234, 236, 239, 244, 246, 249, 250, 254, 256, 262, 263, 264, 267, 268, 269, 270, 271, 276, 279, 280, 286, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 303, 305, 307, 308, 311, 312, 313, 314, 318, 320, 321, 325, 326, 327, 328, 330, 332, 334, 336, 339, 342, 343, 344, 345, 346, 347, 354, 360, 361, 363, 373, 374, 378, 379, 380, 381, 385, 387, 389, 391, 392, 393, 394, 397, 398, 399, 401, 405, 406, 407, 409, 416, 417, 425, 426, 429, 435, 436, 437, 442, 445, 447, 450, 452, 453, 454, 455, 456, 457, 458, 459, 463, 466, 468, 472, 474, 478, 479, 484, 486, 487, 488, 489, 493, 495, 496, 497, 498, 499, 500, 503, 504, 505, 506, 514, 521, 523, 524, 527, 532, 533, 535, 536, 537, 541, 542, 543, 545, 548, 551, 553, 554, 560, 561, 566, 567, 577, 586, 588, 592, 593, 601, 606, 608, 615, 617, 618, 620, 621, 622, 624, 625, 627, 629, 630, 632, 634, 637, 639, 640, 642, 643, 645, 648, 650, 653, 654, 655, 659, 660, 661, 663, 664, 665, 666, 669, 671, 682, 690, 693, 694, 697, 698, 699, 705, 707, 708, 709, 711, 712, 715, 716, 721, 727, 733, 738, 741, 747, 748, 749, 751, 756, 757, 758, 763, 764, 766, 773, 774, 776, 782, 786, 788, 790, 795, 796, 798, 804, 805, 806, 807, 815, 823, 825, 826, 828, 830, 833, 835, 840, 843, 846, 847, 848, 851, 854, 862, 863, 864, 868, 870, 871, 878, 880, 881, 882, 883, 885, 886, 887, 889, 890, 892, 894, 896, 897, 899, 901, 903, 907, 913, 916, 918, 919, 921, 922, 927, 932, 933, 934, 936, 938, 940, 943]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Turn your valid_users (Index or list) into a plain list:\n",
    "valid_users_list = list(valid_users)\n",
    "\n",
    "\n",
    "three_picked = [1,92,433]\n",
    "print(\"Picked users:\", three_picked)\n",
    "remaining_valid_users_list = [u for u in valid_users_list if u not in three_picked]\n",
    "print(\"Remaining valid users:\", remaining_valid_users_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2974874d7e3ef1",
   "metadata": {},
   "source": [
    "selection of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab67734e6e1479c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:26:04.999763Z",
     "start_time": "2025-08-29T13:26:04.553757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_filtered_user_data shape: (362, 4)\n",
      "df_filtered_example_user_data shape: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 7) Sampling helper ---\n",
    "def select_sample(user_ids, k=10, random_state=42):\n",
    "    \"\"\"\n",
    "    For each user:\n",
    "      - ground_truth_total_itemIds: all items (train+test)\n",
    "      - ground_truth_test_itemIds: only test items\n",
    "      - sample_random: up to k random items from their train history, ordered chronologically\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    records = []\n",
    "\n",
    "    for uid in user_ids:\n",
    "        user_all = df_filtered_user_ratings.loc[df_filtered_user_ratings.user_id == uid]\n",
    "        total_items = user_all['movie_id'].tolist()\n",
    "\n",
    "        user_test = test_df.loc[test_df.user_id == uid]\n",
    "        test_items = user_test['movie_id'].tolist()\n",
    "\n",
    "        user_train = train_df.loc[train_df.user_id == uid].copy()\n",
    "\n",
    "        if user_train.empty:\n",
    "            # No train data — keep sample empty but still record ground truth\n",
    "            random_sample = []\n",
    "        else:\n",
    "            # sample up to k rows (no replacement)\n",
    "            n_pick = min(k, len(user_train))\n",
    "            # Use pandas sample with a deterministic seed per user for reproducibility\n",
    "            # Seed is derived from (random_state, uid) so different users differ but are reproducible\n",
    "            seed = (hash((random_state, int(uid))) % (2**32 - 1))\n",
    "            sample_df = (\n",
    "                user_train\n",
    "                .sample(n=n_pick, replace=False, random_state=seed)\n",
    "                .sort_values('date', ascending=True)\n",
    "            )\n",
    "            # keep only movie_id and rating\n",
    "            keep_cols = [c for c in ['movie_id', 'rating'] if c in sample_df.columns]\n",
    "            random_sample = sample_df[keep_cols].values.tolist()\n",
    "\n",
    "        records.append({\n",
    "            'user_id': uid,\n",
    "            'ground_truth_total_itemIds': total_items,\n",
    "            'ground_truth_test_itemIds': test_items,\n",
    "            'sample_random': random_sample\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- 8) Build the two DataFrames ---\n",
    "df_filtered_user_data = select_sample(remaining_valid_users_list)\n",
    "df_filtered_example_user_data = select_sample(three_picked)\n",
    "\n",
    "print(\"df_filtered_user_data shape:\", df_filtered_user_data.shape)\n",
    "print(\"df_filtered_example_user_data shape:\", df_filtered_example_user_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef4572b887c88a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T13:31:53.266904Z",
     "start_time": "2025-08-29T13:31:44.290498Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, re, time, json, random\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from mistralai import Mistral\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "API_KEY = \"\"  # <-- fill this\n",
    "#MODEL_NAME = \"open-mistral-7b\"\n",
    "MODEL_NAME=\"mistral-large-2407\"\n",
    "client = Mistral(api_key=API_KEY)\n",
    "\n",
    "TOP_K = 10\n",
    "NORMAL_TEMPS = [0.0]           # normal run (one file)\n",
    "SC_TEMPS = [0.2, 0.5, 0.7, 1.0]     # self-consistency temperatures\n",
    "MAX_WORKERS = 2           # good balance for a 24-core/120GB machine\n",
    "PAUSE_SECONDS = 1.2\n",
    "\n",
    "OUTPUT_NORMAL = Path(\"mistral-2407/results_normal_revised\")\n",
    "OUTPUT_SC = Path(\"mistral-2407/results_sc\")\n",
    "OUTPUT_NORMAL.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_SC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# DATA ASSUMPTIONS\n",
    "# Must be defined BEFORE running this script:\n",
    "#   df_movies:              ['movie_id', 'title']\n",
    "#   df_genres:              'movie_id' + one-hot genre columns\n",
    "#   df_filtered_user_data:  ['user_id', 'sample_random' (list[(movie_id, rating)])]\n",
    "# =========================\n",
    "assert \"movie_id\" in df_genres.columns, \"df_genres must have 'movie_id'\"\n",
    "assert {\"movie_id\", \"title\"}.issubset(df_movies.columns), \"df_movies needs 'movie_id','title'\"\n",
    "assert \"user_id\" in df_filtered_user_data.columns, \"df_filtered_user_data must have 'user_id'\"\n",
    "\n",
    "# Lookups\n",
    "# Lookups\n",
    "genre_cols = [c for c in df_genres.columns if c != \"movie_id\"]\n",
    "movie_id_to_genres = {\n",
    "    int(row.movie_id): [g for g in genre_cols if int(row[g]) == 1]\n",
    "    for _, row in df_genres.iterrows()\n",
    "}\n",
    "id_to_title = dict(zip(df_movies.movie_id, df_movies.title))\n",
    "title_to_id = dict(zip(df_movies.title.str.strip(), df_movies.movie_id))  # <-- ensure we have this\n",
    "\n",
    "# =========================\n",
    "# FAIRNESS PROMPTS\n",
    "# =========================\n",
    "FAIRNESS_PROMPTS = {\n",
    "    \"neutral\": \"\",\n",
    "}\n",
    "FAIRNESS_LEVELS = ['neutral']\n",
    "\n",
    "# =========================\n",
    "# EXAMPLES (few-shot) loader\n",
    "# expects files like: examples/examples_fair2.json with structure:\n",
    "# { \"random\": [ { \"user_history\": [... or string ...], \"recommendation\": \"1. X, 2. Y, ...\" }, ... ] }\n",
    "# =========================\n",
    "def load_examples():\n",
    "    all_ex = {}\n",
    "    for lvl in FAIRNESS_LEVELS:\n",
    "        fp = Path(f\"examples/examples_{lvl}.json\")\n",
    "        all_ex[lvl] = json.load(fp.open(encoding=\"utf-8\")) if fp.exists() else {}\n",
    "    return all_ex\n",
    "\n",
    "EX_BY_FAIR = load_examples()\n",
    "\n",
    "# =========================\n",
    "# TEMPLATE SETS\n",
    "# A: JSON with ranks   | B: JSON titles only   | C: Plain-text numbered list\n",
    "# (system/user split; {history} only used in user; others via system)\n",
    "# =========================\n",
    "PROMPT_TEMPLATES_A = {\n",
    "    \"zero_shot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"{fairness}Recommend exactly the top-{k} ranked movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates in recommendations.\\n\"\n",
    "            \"- Output a single JSON object and nothing else.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            \"{{\\\"k\\\": {k}, \\\"recommendations\\\": [{\\\"rank\\\": 1, \\\"title\\\": \\\"<Movie 1>\\\"}, ..., \"\n",
    "            \"{\\\"rank\\\": {k}, \\\"title\\\": \\\"<Movie {k}>\\\"}]}}\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"few_shot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"Below are demonstrated examples (no reasoning shown). Each example shows a user's history and a FINAL_JSON object that follows the strict schema.\\n\"\n",
    "            \"{fairness}Recommend exactly the top-{k} ranked movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates in recommendations.\\n\"\n",
    "            \"- Output a single JSON object and nothing else.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            \"{{\\\"k\\\": {k}, \\\"recommendations\\\": [{\\\"rank\\\": 1, \\\"title\\\": \\\"<Movie 1>\\\"}, ..., \"\n",
    "            \"{\\\"rank\\\": {k}, \\\"title\\\": \\\"<Movie {k}>\\\"}]}}\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"zero_shot_cot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"{fairness}Recommend exactly the top-{k} ranked movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates in recommendations.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            \"{{\\\"k\\\": {k}, \\\"recommendations\\\": [{\\\"rank\\\": 1, \\\"title\\\": \\\"<Movie 1>\\\"}, ..., \"\n",
    "            \"{\\\"rank\\\": {k}, \\\"title\\\": \\\"<Movie {k}>\\\"}]}}\\n\"\n",
    "            \"Before answering, LET'S THINK STEP BY STEP.\\n\"\n",
    "\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"few_shot_cot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"Below are demonstrated examples (no reasoning shown). Each example shows a user's history and a FINAL_JSON object that follows the strict schema.\\n\"\n",
    "            \"{fairness}Recommend exactly the top-{k} ranked movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates in recommendations.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            \"{{\\\"k\\\": {k}, \\\"recommendations\\\": [{\\\"rank\\\": 1, \\\"title\\\": \\\"<Movie 1>\\\"}, ..., \"\n",
    "            \"{\\\"rank\\\": {k}, \\\"title\\\": \\\"<Movie {k}>\\\"}]}}\\n\"\n",
    "            \"Before answering, LET'S THINK STEP BY STEP.\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "}\n",
    "\n",
    "PROMPT_TEMPLATES_B = {\n",
    "    \"zero_shot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"{fairness}Recommend exactly top-{k} movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"- Output a single JSON object and nothing else.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            '{{\\\"k\\\": {k}, \\\"recommendations\\\": [\\\"<Movie 1>\\\", \\\"<Movie 2>\\\", ..., \\\"<Movie {k}>\\\"]}}'\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"few_shot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"Below are demonstrated examples (no reasoning shown). Each example shows a user's history and a FINAL_JSON object that follows the strict schema.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"- Output a single JSON object and nothing else.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            '{{\\\"k\\\": {k}, \\\"recommendations\\\": [\\\"<Movie 1>\\\", \\\"<Movie 2>\\\", ..., \\\"<Movie {k}>\\\"]}}'\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"zero_shot_cot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"{fairness}Recommend exactly top-{k} movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            '{{\\\"k\\\": {k}, \\\"recommendations\\\": [\\\"<Movie 1>\\\", \\\"<Movie 2>\\\", ..., \\\"<Movie {k}>\\\"]}}\\n'\n",
    "            \"Before answering, LET'S THINK STEP BY STEP.\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"few_shot_cot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"Below are demonstrated examples (no reasoning shown). Each example shows a user's history and a FINAL_JSON object that follows the strict schema.\\n\"\n",
    "            \"{fairness}Recommend exactly top-{k} movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"SCHEMA (STRICT):\\n\"\n",
    "            '{{\\\"k\\\": {k}, \\\"recommendations\\\": [\\\"<Movie 1>\\\", \\\"<Movie 2>\\\", ..., \\\"<Movie {k}>\\\"]}}\\n'\n",
    "            \"Before answering, LET'S THINK STEP BY STEP.\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "}\n",
    "\n",
    "PROMPT_TEMPLATES_C = {\n",
    "    \"zero_shot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"{fairness}Recommend exactly top-{k} movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"- Output EXACTLY this plain-text format (no extra text):\\n\"\n",
    "            \"RECOMMENDATIONS:\\n1) <Movie 1>\\n2) <Movie 2>\\n...\\n{k}) <Movie {k}>\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"few_shot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"Below are demonstrated examples (no reasoning shown). Each example shows a user's history and the response.\\n\"\n",
    "            \"{fairness}Recommend exactly top-{k} movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"- Output EXACTLY this plain-text format (no extra text):\\n\"\n",
    "            \"RECOMMENDATIONS:\\n1) <Movie 1>\\n2) <Movie 2>\\n...\\n{k}) <Movie {k}>\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"zero_shot_cot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"{fairness}Recommend exactly top-{k} movies.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"- Follow output format:\\n\"\n",
    "            \"RECOMMENDATIONS:\\n1) <Movie 1>\\n2) <Movie 2>\\n...\\n{k}) <Movie {k}>\\n\"\n",
    "            \"Before answering, LET'S THINK STEP BY STEP.\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "    \"few_shot_cot\": {\n",
    "        \"system\": (\n",
    "            \"You are a helpful movie recommender.\\n\"\n",
    "            \"Below are demonstrated examples (no reasoning shown). Each example shows a user's history and the response.\\n\"\n",
    "            \"RULES (STRICT):\\n\"\n",
    "            \"- Recommend {k} distinct movies not present in the watched list below.\\n\"\n",
    "            \"- No duplicates.\\n\"\n",
    "            \"- Follow output format:\\n\"\n",
    "            \"RECOMMENDATIONS:\\n1) <Movie 1>\\n2) <Movie 2>\\n...\\n{k}) <Movie {k}>\\n\"\n",
    "            \"Before answering, LET'S THINK STEP BY STEP.\\n\"\n",
    "        ),\n",
    "        \"user\": \"User's watched movies (exclude all of these in recommendation):\\n{history}\"\n",
    "    },\n",
    "}\n",
    "\n",
    "TEMPLATE_SETS = {\"A\": PROMPT_TEMPLATES_A, \"B\": PROMPT_TEMPLATES_B} if False else {\"A\": PROMPT_TEMPLATES_A, \"B\": PROMPT_TEMPLATES_B, \"C\": PROMPT_TEMPLATES_C}\n",
    "\n",
    "def _clean_title(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize example titles:\n",
    "    - coerce to str\n",
    "    - strip whitespace\n",
    "    - drop a trailing comma (e.g., 'Copycat (1995),')\n",
    "    \"\"\"\n",
    "    return re.sub(r'[,\\s]+$', '', str(s).strip())\n",
    "\n",
    "def _format_example_history_from_titles(titles, default_rating=3):\n",
    "    \"\"\"\n",
    "    Build a numbered history (same style as real prompts) from a list of titles.\n",
    "    Example output:\n",
    "      1. \"Toy Story (1995)\" – Animation|Children's|Comedy (rating 3)\n",
    "      2. \"Rumble in the Bronx (1995)\" – Action|Adventure|Crime (rating 3)\n",
    "    \"\"\"\n",
    "    if not titles:\n",
    "        return \"\"\n",
    "\n",
    "    lines = []\n",
    "    for idx, raw in enumerate(titles, start=1):\n",
    "        t = _clean_title(raw)\n",
    "        mid = title_to_id.get(t)\n",
    "        if mid is not None:\n",
    "            genres = movie_id_to_genres.get(int(mid), [])\n",
    "            gtxt = \"|\".join(genres) if genres else \"Unknown\"\n",
    "        else:\n",
    "            # Title not found in df_movies (spelling/variant) → still render gracefully\n",
    "            gtxt = \"Unknown\"\n",
    "        lines.append(f'{idx}. \"{t}\" – {gtxt} (rating {default_rating})')\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _history_text_from_example(hist):\n",
    "    \"\"\"\n",
    "    Previously this returned a bullet list. Now it returns the SAME formatted\n",
    "    numbered history used for real prompts, with genres + a default rating.\n",
    "    - If 'hist' is a list of titles, format using df lookups.\n",
    "    - If 'hist' is a string, try to split by lines/commas; otherwise render as-is.\n",
    "    \"\"\"\n",
    "    if isinstance(hist, list):\n",
    "        return \"User's watched movies (exclude all of these in recommendation):\\n\" + _format_example_history_from_titles(hist)\n",
    "    # If string, try to split on newlines, else commas → then format\n",
    "    s = str(hist or \"\").strip()\n",
    "    if not s:\n",
    "        return \"User's watched movies (exclude all of these in recommendation):\\n\"\n",
    "    # try newline first, fallback to commas\n",
    "    parts = [p for p in re.split(r\"\\n+\", s) if p.strip()] or [p for p in s.split(\",\") if p.strip()]\n",
    "    return \"User's watched movies (exclude all of these in recommendation):\\n\" + _format_example_history_from_titles(parts)\n",
    "\n",
    "_REC_ITEM_RE = re.compile(r'(\\d+)\\.\\s*(.+?)(?=(?:\\s*,\\s*\\d+\\.\\s*)|$)')\n",
    "\n",
    "def _ranked_obj_from_titles(titles, k_default=10):\n",
    "    titles = [str(t).strip() for t in titles if str(t).strip()]\n",
    "    items = [{\"rank\": i, \"title\": t} for i, t in enumerate(titles[:k_default], start=1)]\n",
    "    if not items:\n",
    "        items = [{\"rank\": i, \"title\": f\"<Movie {i}>\"} for i in range(1, k_default + 1)]\n",
    "    return {\"k\": len(items), \"recommendations\": items}\n",
    "\n",
    "def recommendation_line_to_json_obj(rec_any, k_default: int = 10):\n",
    "    if isinstance(rec_any, dict) and \"recommendations\" in rec_any:\n",
    "        items = []\n",
    "        for i, it in enumerate(rec_any.get(\"recommendations\", []), start=1):\n",
    "            if isinstance(it, dict):\n",
    "                title = it.get(\"title\") or it.get(\"name\") or str(it)\n",
    "                rank = int(it.get(\"rank\", i))\n",
    "            else:\n",
    "                title = str(it)\n",
    "                rank = i\n",
    "            items.append({\"rank\": int(rank), \"title\": str(title)})\n",
    "        items = sorted(items, key=lambda x: x[\"rank\"])[:k_default]\n",
    "        if not items:\n",
    "            items = [{\"rank\": i, \"title\": f\"<Movie {i}>\"} for i in range(1, k_default + 1)]\n",
    "        return {\"k\": len(items), \"recommendations\": items}\n",
    "\n",
    "    if isinstance(rec_any, list):\n",
    "        titles = []\n",
    "        for i, it in enumerate(rec_any, start=1):\n",
    "            if isinstance(it, dict):\n",
    "                t = it.get(\"title\") or it.get(\"name\") or str(it)\n",
    "            else:\n",
    "                t = str(it)\n",
    "            t = t.strip()\n",
    "            if t:\n",
    "                titles.append(t)\n",
    "        return _ranked_obj_from_titles(titles, k_default=k_default)\n",
    "\n",
    "    rec_text = (rec_any or \"\").strip()\n",
    "    if rec_text.startswith(\"{\"):\n",
    "        try:\n",
    "            obj = json.loads(rec_text)\n",
    "            if isinstance(obj, dict) and \"recommendations\" in obj:\n",
    "                return recommendation_line_to_json_obj(obj, k_default=k_default)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    items = []\n",
    "    for m in _REC_ITEM_RE.finditer(rec_text):\n",
    "        try:\n",
    "            rank = int(m.group(1))\n",
    "        except Exception:\n",
    "            continue\n",
    "        title = m.group(2).strip().rstrip(\", \").replace(\" …\", \"\").replace(\"...\", \"\").strip()\n",
    "        items.append({\"rank\": rank, \"title\": title})\n",
    "\n",
    "    if not items:\n",
    "        if \",\" in rec_text:\n",
    "            titles = [t.strip() for t in rec_text.split(\",\") if t.strip()]\n",
    "            return _ranked_obj_from_titles(titles, k_default=k_default)\n",
    "        return _ranked_obj_from_titles([], k_default=k_default)\n",
    "\n",
    "    items = sorted(items, key=lambda x: x[\"rank\"])[:k_default]\n",
    "    return {\"k\": len(items), \"recommendations\": items}\n",
    "\n",
    "def _assistant_text_for_set_A(rec_any, k_default=10):\n",
    "    obj = recommendation_line_to_json_obj(rec_any, k_default=k_default)\n",
    "    return json_compact(obj)\n",
    "\n",
    "def _assistant_text_for_set_B(rec_any, k_default=10):\n",
    "    objA = recommendation_line_to_json_obj(rec_any, k_default=k_default)\n",
    "    titles = [r[\"title\"] for r in objA.get(\"recommendations\", [])]\n",
    "    return json_compact({\"k\": len(titles), \"recommendations\": titles})\n",
    "\n",
    "def _assistant_text_for_set_C(rec_any, k_default=10):\n",
    "    objA = recommendation_line_to_json_obj(rec_any, k_default=k_default)\n",
    "    titles = [r[\"title\"] for r in objA.get(\"recommendations\", [])]\n",
    "    lines = [\"RECOMMENDATIONS:\"] + [f\"{i}) {t}\" for i, t in enumerate(titles, start=1)]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def json_compact(obj) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "\n",
    "\n",
    "def build_example_turns(set_name: str, fairness: str, k_default=10, max_examples=2, strategy=\"random\"):\n",
    "    ex_list = EX_BY_FAIR.get(fairness, {}).get(strategy, [])\n",
    "    if not ex_list:\n",
    "        return []\n",
    "    turns = []\n",
    "    for ex in ex_list[:max_examples]:\n",
    "        u_hist = _history_text_from_example(ex.get(\"user_history\", \"\"))\n",
    "        if set_name == \"A\":\n",
    "            a_out = _assistant_text_for_set_A(ex.get(\"recommendation\", \"\"), k_default)\n",
    "        elif set_name == \"B\":\n",
    "            a_out = _assistant_text_for_set_B(ex.get(\"recommendation\", \"\"), k_default)\n",
    "        else:\n",
    "            a_out = _assistant_text_for_set_C(ex.get(\"recommendation\", \"\"), k_default)\n",
    "        turns.append({\"role\": \"user\", \"content\": u_hist})\n",
    "        turns.append({\"role\": \"assistant\", \"content\": a_out})\n",
    "    return turns\n",
    "\n",
    "# =========================\n",
    "# BUILD MESSAGES (system + few-shot dialogue turns + real user)\n",
    "# =========================\n",
    "def render(text: str, **vals) -> str:\n",
    "    for k, v in vals.items():\n",
    "        text = text.replace(\"{\"+k+\"}\", str(v))\n",
    "    return text\n",
    "\n",
    "def format_history(pairs):\n",
    "    if not pairs: return \"\"\n",
    "    lines = []\n",
    "    for i, (mid, rating) in enumerate(pairs, start=1):\n",
    "        title = id_to_title.get(mid, f\"Unknown({mid})\")\n",
    "        genres = movie_id_to_genres.get(mid, [])\n",
    "        gtxt = \"|\".join(genres) if genres else \"Unknown\"\n",
    "        rtxt = rating if pd.notna(rating) else \"N/A\"\n",
    "        lines.append(f'{i}. \"{title}\" – {gtxt} (rating {rtxt})')\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def build_messages(set_name, style, fairness_key, k, real_history_text):\n",
    "    fairness_text = FAIRNESS_PROMPTS.get(fairness_key, \"\")\n",
    "    tpl = TEMPLATE_SETS[set_name][style]\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": render(tpl[\"system\"], fairness=fairness_text, k=k)}]\n",
    "\n",
    "    if \"few_shot\" in style:\n",
    "        messages.extend(build_example_turns(set_name, fairness_key, k_default=k, max_examples=2, strategy=\"random\"))\n",
    "\n",
    "    user_text = render(tpl[\"user\"], history=real_history_text, k=k)\n",
    "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    print(\"\\n=== BUILT MESSAGES ===\")\n",
    "    for m in messages:\n",
    "        role = m[\"role\"].upper()\n",
    "        print(f\"[{role}]\\n{m['content']}\\n\")\n",
    "    print(\"======================\\n\")\n",
    "\n",
    "    return messages\n",
    "\n",
    "def chat_once(messages, temperature):\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            print(f\"--> Sending to Mistral @ T={temperature}\")\n",
    "            resp = client.chat.complete(\n",
    "                model=MODEL_NAME,\n",
    "                temperature=temperature,\n",
    "                messages=messages\n",
    "            )\n",
    "            answer = resp.choices[0].message.content.strip()\n",
    "            print(\"=== MODEL RESPONSE ===\")\n",
    "            print(answer)\n",
    "            print(\"======================\\n\")\n",
    "\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}, retrying...\")\n",
    "            time.sleep(PAUSE_SECONDS)\n",
    "    return \"ERROR\"\n",
    "\n",
    "def mistral_complete(messages, temperature: float, n: int = 1, max_retries: int = 5):\n",
    "    \"\"\"\n",
    "    Call Mistral repeatedly in batches of up to 10 to reach n completions.\n",
    "    \"\"\"\n",
    "    max_per_call = 10\n",
    "    collected = []\n",
    "    delay = PAUSE_SECONDS\n",
    "\n",
    "    while len(collected) < n:\n",
    "        need = min(max_per_call, n - len(collected))\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                print(f\"--> Mistral call @ T={temperature}, batch={need}, collected={len(collected)}/{n}\")\n",
    "                resp = client.chat.complete(\n",
    "                    model=MODEL_NAME,\n",
    "                    temperature=temperature,\n",
    "                    n=need,\n",
    "                    messages=messages\n",
    "                )\n",
    "                for ch in resp.choices:\n",
    "                    collected.append(ch.message.content.strip())\n",
    "                break  # success → move to next batch\n",
    "            except Exception as e:\n",
    "                print(f\"[mistral_complete] Error: {e} (attempt {attempt}/{max_retries})\")\n",
    "                time.sleep(delay)\n",
    "                delay = min(delay * 2, 8.0)\n",
    "        else:\n",
    "            # after max_retries\n",
    "            collected.extend([\"ERROR\"] * need)\n",
    "\n",
    "    return collected[:n]\n",
    "\n",
    "# =========================\n",
    "# RUNNERS\n",
    "# =========================\n",
    "def _load_done_index_from_jsonl(path: Path):\n",
    "    \"\"\"\n",
    "    Reads an existing JSONL file and returns a set of keys for already-completed records.\n",
    "    Key schema: (user_id, template_set, style, fairness, temperature)\n",
    "    \"\"\"\n",
    "    done = set()\n",
    "    if not path.exists():\n",
    "        return done\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                key = (\n",
    "                    int(obj.get(\"user_id\")),\n",
    "                    obj.get(\"template_set\"),\n",
    "                    obj.get(\"style\"),\n",
    "                    obj.get(\"fairness\"),\n",
    "                    float(obj.get(\"temperature\", 0.0)),\n",
    "                )\n",
    "                done.add(key)\n",
    "            except Exception:\n",
    "                # skip malformed lines, don't crash resume\n",
    "                continue\n",
    "    return done\n",
    "\n",
    "\n",
    "def run_normal_t0(df_users, template_sets=(\"A\",\"B\",\"C\")):\n",
    "    \"\"\"\n",
    "    Normal run @ T=0.0 for all sets (A,B,C) and styles (zero_shot, few_shot, zero_shot_cot, few_shot_cot).\n",
    "    Writes each record to JSONL immediately and supports resume by skipping already written items.\n",
    "    \"\"\"\n",
    "    out_path = OUTPUT_NORMAL / \"normal_t0.jsonl\"\n",
    "    done = _load_done_index_from_jsonl(out_path)\n",
    "\n",
    "    # Build all tasks, skipping those already completed\n",
    "    tasks = []\n",
    "    for _, row in df_users.iterrows():\n",
    "        uid = int(row.user_id)\n",
    "        history_text = format_history(row.get(\"sample_random\", []))\n",
    "        for set_name in template_sets:\n",
    "            for style in TEMPLATE_SETS[set_name].keys():\n",
    "                for fair in FAIRNESS_LEVELS:\n",
    "                    key = (uid, set_name, style, fair, 0.0)\n",
    "                    if key in done:\n",
    "                        continue\n",
    "                    tasks.append((uid, set_name, style, fair, history_text))\n",
    "\n",
    "    if not tasks:\n",
    "        print(f\"[Normal] Nothing to do. All results already present in {out_path}\")\n",
    "        return\n",
    "\n",
    "    # Open for append; write/flush each result ASAP\n",
    "    with out_path.open(\"a\", encoding=\"utf-8\") as f_out:\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:\n",
    "            futures = []\n",
    "            for uid, set_name, style, fair, history_text in tasks:\n",
    "                print(f\"Running NORMAL: user={uid}, set={set_name}, style={style}, fairness={fair}\")\n",
    "                msgs = build_messages(set_name, style, fair, TOP_K, history_text)\n",
    "                futures.append(\n",
    "                        pool.submit(\n",
    "                        lambda u=uid, sn=set_name, st=style, fk=fair, m=msgs:\n",
    "                        (u, sn, st, fk, 0.0, chat_once(m, 0.0), m)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "            for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Normal T=0.0\"):\n",
    "                try:\n",
    "                    user_id, set_name, style, fair, temp, answer, msgs = fut.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"[Normal] Future failed: {e}\")\n",
    "                    continue\n",
    "\n",
    "                record = {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"template_set\": set_name,\n",
    "                    \"style\": style,\n",
    "                    \"fairness\": fair,\n",
    "                    \"temperature\": temp,\n",
    "                    \"messages\": msgs,\n",
    "                    \"response\": answer\n",
    "                }\n",
    "\n",
    "                # Write ASAP + force flush so you can resume safely after interruptions\n",
    "                f_out.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                f_out.flush()\n",
    "                os.fsync(f_out.fileno())\n",
    "\n",
    "\n",
    "def run_sc(df_users, temps=(0.2,0.5,0.7,1.0), template_sets=(\"A\",\"B\",\"C\"), N=20):\n",
    "    cot_styles = [\"zero_shot_cot\", \"few_shot_cot\"]\n",
    "\n",
    "    for _, row in df_users.iterrows():\n",
    "        uid = int(row.user_id)\n",
    "        history_text = format_history(row.get(\"sample_random\", []))\n",
    "\n",
    "        for set_name in template_sets:\n",
    "            for t in temps:\n",
    "                base = OUTPUT_SC / f\"user_{uid}\" / set_name / f\"temp_{t}\"\n",
    "                base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                for style in cot_styles:\n",
    "                    for fair in FAIRNESS_LEVELS:\n",
    "                        out_file = base / f\"{style}__{fair}.json\"\n",
    "                        if out_file.exists():\n",
    "                            print(f\"[Skip] {out_file} already exists\")\n",
    "                            continue\n",
    "\n",
    "                        print(f\"Running SC: user={uid}, set={set_name}, style={style}, fairness={fair}, temp={t}, N={N}\")\n",
    "                        msgs = build_messages(set_name, style, fair, TOP_K, history_text)\n",
    "\n",
    "                        # ---- ONE API call returns N completions ----\n",
    "                        completions = mistral_complete(msgs, temperature=t, n=N)\n",
    "\n",
    "                        if not completions:\n",
    "                            samples = [{\"sample_id\": i + 1, \"response\": \"ERROR: empty\"} for i in range(N)]\n",
    "                        else:\n",
    "                            samples = [{\"sample_id\": i + 1, \"response\": txt} for i, txt in enumerate(completions)]\n",
    "\n",
    "                        record = {\n",
    "                            \"user_id\": uid,\n",
    "                            \"template_set\": set_name,\n",
    "                            \"style\": style,\n",
    "                            \"fairness\": fair,\n",
    "                            \"temperature\": t,\n",
    "                            \"messages\": msgs,\n",
    "                            \"samples\": samples\n",
    "                        }\n",
    "                        with out_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                            json.dump(record, f, ensure_ascii=False, indent=2)\n",
    "                            f.flush()\n",
    "                            os.fsync(f.fileno())\n",
    "\n",
    "# =========================\n",
    "# NORMAL RUNS FOR TEMPLATE B @ EXTRA TEMPS\n",
    "# =========================\n",
    "NORMAL_EXTRA_TEMPS = [0.2, 0.5, 0.7, 1.0]\n",
    "\n",
    "def run_normal_templateB(\n",
    "    df_users,\n",
    "    temps=NORMAL_EXTRA_TEMPS,\n",
    "    styles=(\"zero_shot\", \"few_shot\", \"zero_shot_cot\", \"few_shot_cot\")\n",
    "):\n",
    "    \"\"\"\n",
    "    For Template Set C only, run normal single-completion calls at the given temperatures\n",
    "    across the provided styles. Writes one JSONL per temperature and supports resume.\n",
    "    \"\"\"\n",
    "    for temp in temps:\n",
    "        # nice filename like normal_B_t0p2.jsonl, normal_B_t1.jsonl, etc.\n",
    "        ttag = str(temp).replace(\".\", \"p\")\n",
    "        out_path = OUTPUT_NORMAL / f\"normal_C_t{ttag}.jsonl\"\n",
    "        done = _load_done_index_from_jsonl(out_path)\n",
    "\n",
    "        # Build tasks, skipping already-completed (resume-friendly)\n",
    "        tasks = []\n",
    "        for _, row in df_users.iterrows():\n",
    "            uid = int(row.user_id)\n",
    "            history_text = format_history(row.get(\"sample_random\", []))\n",
    "            for fair in FAIRNESS_LEVELS:\n",
    "                for style in styles:\n",
    "                    key = (uid, \"B\", style, fair, float(temp))\n",
    "                    if key in done:\n",
    "                        continue\n",
    "                    tasks.append((uid, \"B\", style, fair, history_text, temp))\n",
    "\n",
    "        if not tasks:\n",
    "            print(f\"[Normal-C@T={temp}] Nothing to do. All results already present in {out_path}\")\n",
    "            continue\n",
    "\n",
    "        with out_path.open(\"a\", encoding=\"utf-8\") as f_out:\n",
    "            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:\n",
    "                futures = []\n",
    "                for uid, set_name, style, fair, history_text, t in tasks:\n",
    "                    print(f\"Running NORMAL-B: user={uid}, style={style}, fairness={fair}, T={t}\")\n",
    "                    msgs = build_messages(set_name, style, fair, TOP_K, history_text)\n",
    "                    futures.append(\n",
    "                        pool.submit(\n",
    "                            lambda u=uid, sn=set_name, st=style, fk=fair, m=msgs, tt=t:\n",
    "                                (u, sn, st, fk, tt, chat_once(m, tt), m)\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                for fut in tqdm(as_completed(futures), total=len(futures), desc=f\"Normal B T={temp}\"):\n",
    "                    try:\n",
    "                        user_id, set_name, style, fair, temp_used, answer, msgs = fut.result()\n",
    "                    except Exception as e:\n",
    "                        print(f\"[Normal-C@T={temp}] Future failed: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    record = {\n",
    "                        \"user_id\": user_id,\n",
    "                        \"template_set\": set_name,  # \"B\"\n",
    "                        \"style\": style,\n",
    "                        \"fairness\": fair,\n",
    "                        \"temperature\": float(temp_used),\n",
    "                        \"messages\": msgs,\n",
    "                        \"response\": answer\n",
    "                    }\n",
    "                    f_out.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                    f_out.flush()\n",
    "                    os.fsync(f_out.fileno())\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# SELECT USERS & RUN\n",
    "# =========================\n",
    "# Pick 30 users deterministically\n",
    "all_user_ids = df_filtered_user_data[\"user_id\"].dropna().astype(int).unique().tolist()\n",
    "random.seed(42)\n",
    "picked = sorted(random.sample(all_user_ids, k=min(100, len(all_user_ids))))\n",
    "print(\"Selected 100 user IDs:\", picked)\n",
    "\n",
    "users_to_run = df_filtered_user_data[df_filtered_user_data[\"user_id\"].isin(picked)].copy()\n",
    "\n",
    "\n",
    "print(\"Running for users:\", users_to_run[\"user_id\"].unique().tolist())\n",
    "#run_normal_templateB(users_to_run, temps=[0.2, 0.5, 0.7, 1.0],\n",
    " #                    styles=(\"zero_shot\", \"few_shot\", \"zero_shot_cot\", \"few_shot_cot\"))\n",
    "\n",
    "# 1) Normal run @ T=0.0 (single file)\n",
    "run_normal_t0(users_to_run, template_sets=(\"A\",\"B\",\"C\"))\n",
    "\n",
    "#run_normal_templateC(users_to_run, temps=[0.2, 0.5, 0.7, 1.0],styles=(\"zero_shot\", \"few_shot\", \"zero_shot_cot\", \"few_shot_cot\"))\n",
    "\n",
    "# 2) Self-consistency CoT runs (per-temp → per-user → per (style×fairness) file)\n",
    "#run_sc(users_to_run, temps=SC_TEMPS, template_sets=(\"B\"))\n",
    "\n",
    "\n",
    "print(\"✓ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cdc73-9aaa-4282-8a32-c137ab9113b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e433f-9266-4988-b896-e080a58ffe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658e9b7-0a4c-4ce5-8a10-d66959ed06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
