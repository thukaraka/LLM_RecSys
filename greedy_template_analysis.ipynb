{
 "cells": [
  {
   "cell_type": "code",
   "id": "03bb21bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:45:30.892392Z",
     "start_time": "2025-10-25T00:45:30.413513Z"
    }
   },
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from narwhals import read_csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ── Config ──\n",
    "FILE_PATH = Path(\"data/gpt_4o/results_normal_revised/normal_t0.jsonl\")\n",
    "MAX_K = 10\n",
    "\n",
    "# ── Regexes (precompiled) ──\n",
    "RE_CODE_FENCE = re.compile(r\"^```(?:json)?|```$\", re.MULTILINE)\n",
    "RE_JSON_BLOCK = re.compile(r'[{]{1,2}[\\s\\S]*?\"recommendations\"\\s*:\\s*\\[.*?\\][\\s\\S]*?[}]{1,2}', re.DOTALL)\n",
    "RE_RECS_ARRAY = re.compile(r'\"recommendations\"\\s*:\\s*\\[(.*?)\\]', re.DOTALL)\n",
    "RE_COMMENTS_LINE = re.compile(r'//.*')\n",
    "RE_COMMENTS_BLOCK = re.compile(r'/\\*[\\s\\S]*?\\*/')\n",
    "RE_TRAILING_COMMA = re.compile(r',\\s*([}\\]])')\n",
    "RE_NUMBERED_LINE = re.compile(r'^\\s*\\d+[.)]\\s+(.*)$')  # capture rest of the line\n",
    "RE_QUOTED_TITLE = re.compile(r'^\\s*\"([^\"]+)\"\\s*$')\n",
    "RE_TITLE_YEAR_1 = re.compile(r'^\\s*\"([^\"]+\\(\\d{4}\\))\"\\s*$')          # \"Title (Year)\"\n",
    "RE_TITLE_YEAR_2 = re.compile(r'^\\s*\"([^\"]+)\"\\s*\\((\\d{4})\\)\\s*$')     # \"Title\" (Year)\n",
    "RE_TITLE_YEAR_3 = re.compile(r'^\\s*([^(]+)\\s*\\((\\d{4})\\)\\s*$')       # Title (Year)\n",
    "RE_QUOTE_STRIP = re.compile(r'^[\\'\"]|[\\'\"]$')\n",
    "\n",
    "\n",
    "def _strip_code_fences(s: str) -> str:\n",
    "    return RE_CODE_FENCE.sub('', s)\n",
    "\n",
    "def _clean_jsonish(s: str) -> str:\n",
    "    s = _strip_code_fences(s)\n",
    "    s = RE_COMMENTS_LINE.sub('', s)      # remove // ...\n",
    "    s = RE_COMMENTS_BLOCK.sub('', s)     # remove /* ... */\n",
    "    s = RE_TRAILING_COMMA.sub(r'\\1', s)  # remove trailing commas\n",
    "    \n",
    "    # Additional cleaning for genre removal in JSON strings\n",
    "    # Remove inline comments that might contain genres\n",
    "    s = re.sub(r'//\\s*[A-Za-z\\s|]+$', '', s, flags=re.MULTILINE)\n",
    "    \n",
    "    # Clean up any malformed JSON with genres in strings\n",
    "    # This handles cases like: \"Movie Title (Year) - Drama\"\n",
    "    s = re.sub(r'\"([^\"]*)\\s*[-–—]\\s*[A-Za-z\\s|]+\"', r'\"\\1\"', s)\n",
    "    \n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RE_DASH_SPLIT   = re.compile(r'\\s*[–—-]\\s*')           # en dash, em dash, hyphen\n",
    "RE_SMART_QUOTES = re.compile(r'^[\\s\"“\"''«»]+|[\\s\"“\"''«»]+$')\n",
    "RE_WS_COLLAPSE  = re.compile(r'\\s+')\n",
    "# Enhanced regex for genre removal - handles various patterns\n",
    "RE_GENRE_REMOVAL = re.compile(r'\\s*[-–—]\\s*[^()]*$')  # Remove everything after dash/hyphen\n",
    "RE_GENRE_REMOVAL_2 = re.compile(r'\\s*[-–—]\\s*[A-Za-z\\s|]+$')  # Remove genre patterns like \" - Drama|Action\"\n",
    "RE_GENRE_REMOVAL_3 = re.compile(r'\\s*[-–—]\\s*[A-Za-z\\s|]+$')  # Another pattern\n",
    "RE_GENRE_REMOVAL_4 = re.compile(r'\\s*[-–—]\\s*[^()]*\\s*$')  # More general pattern\n",
    "\n",
    "def _norm_title(t: str) -> str:\n",
    "    if not isinstance(t, str):\n",
    "        return \"\"\n",
    "    t = t.strip()\n",
    "    \n",
    "    # Remove genres more aggressively - handle multiple patterns\n",
    "    # Pattern 1: Remove everything after dash/hyphen (most common)\n",
    "    t = re.sub(r'\\s*[-–—]\\s*[^()]*$', '', t)\n",
    "    \n",
    "    # Pattern 2: Remove genre patterns like \" - Drama|Action\"\n",
    "    t = re.sub(r'\\s*[-–—]\\s*[A-Za-z\\s|]+$', '', t)\n",
    "    \n",
    "    # Pattern 3: Remove genre patterns with parentheses like \" - (Drama)\"\n",
    "    t = re.sub(r'\\s*[-–—]\\s*\\([^)]*\\)$', '', t)\n",
    "    \n",
    "    # Pattern 4: Remove genre patterns with brackets like \" - [Drama]\"\n",
    "    t = re.sub(r'\\s*[-–—]\\s*\\[[^\\]]*\\]$', '', t)\n",
    "    \n",
    "    # Pattern 5: Remove any remaining genre-like text after dashes\n",
    "    t = re.sub(r'\\s*[-–—]\\s*[A-Za-z\\s|&]+$', '', t)\n",
    "    \n",
    "    # Pattern 6: Handle cases where genres are separated by pipes\n",
    "    t = re.sub(r'\\s*[-–—]\\s*[A-Za-z]+(\\|[A-Za-z]+)*$', '', t)\n",
    "    \n",
    "    # Remove any remaining genre-like patterns\n",
    "    # Look for patterns like \" - Genre\" or \" – Genre\" at the end\n",
    "    t = re.sub(r'\\s*[-–—]\\s*[A-Za-z\\s|&]+$', '', t)\n",
    "    \n",
    "    # Clean up any remaining quotes and whitespace\n",
    "    t = RE_SMART_QUOTES.sub('', t)       # strip ASCII + smart quotes at ends\n",
    "    t = RE_WS_COLLAPSE.sub(' ', t)       # collapse whitespace\n",
    "    \n",
    "    # Final cleanup - remove any trailing punctuation that might be left\n",
    "    t = re.sub(r'\\s*[-–—]\\s*$', '', t)\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "def _dedupe_preserve_order(items):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in items:\n",
    "        if x and x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "def _from_json_object(response: str, k=MAX_K):\n",
    "    \"\"\"\n",
    "    Strict JSON block: parse whole object and read .recommendations\n",
    "    \"\"\"\n",
    "    s = _clean_jsonish(response)\n",
    "    if not (s.startswith('{') and s.endswith('}')):\n",
    "        return []\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "        recs = obj.get(\"recommendations\", [])\n",
    "        titles = []\n",
    "        if isinstance(recs, list):\n",
    "            for r in recs:\n",
    "                if isinstance(r, dict) and \"title\" in r:\n",
    "                    titles.append(_norm_title(str(r[\"title\"])))\n",
    "                elif isinstance(r, str):\n",
    "                    # Handle strings that might contain genres\n",
    "                    clean_title = _norm_title(r)\n",
    "                    titles.append(clean_title)\n",
    "        return titles[:k]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def _from_embedded_json(response: str, k=MAX_K):\n",
    "    \"\"\"\n",
    "    JSON-ish block embedded in prose: find block, clean, parse\n",
    "    \"\"\"\n",
    "    m = RE_JSON_BLOCK.search(response)\n",
    "    if not m:\n",
    "        return []\n",
    "    block = _clean_jsonish(m.group(0))\n",
    "    # Try as-is\n",
    "    try:\n",
    "        obj = json.loads(block)\n",
    "        recs = obj.get(\"recommendations\", [])\n",
    "        titles = []\n",
    "        for r in recs:\n",
    "            if isinstance(r, dict) and \"title\" in r:\n",
    "                titles.append(_norm_title(str(r[\"title\"])))\n",
    "            elif isinstance(r, str):\n",
    "                # Handle strings that might contain genres\n",
    "                clean_title = _norm_title(r)\n",
    "                titles.append(clean_title)\n",
    "        return titles[:k]\n",
    "    except Exception:\n",
    "        # Fallback: extract just the array text and parse it as JSON list\n",
    "        m2 = RE_RECS_ARRAY.search(block)\n",
    "        if not m2:\n",
    "            return []\n",
    "        raw = \"[\" + m2.group(1) + \"]\"\n",
    "        raw = _clean_jsonish(raw)\n",
    "        # Attempt to turn into a valid JSON list of strings\n",
    "        try:\n",
    "            arr = json.loads(raw)\n",
    "            titles = []\n",
    "            for r in arr:\n",
    "                if isinstance(r, dict) and \"title\" in r:\n",
    "                    titles.append(_norm_title(str(r[\"title\"])))\n",
    "                elif isinstance(r, str):\n",
    "                    # Handle strings that might contain genres\n",
    "                    clean_title = _norm_title(r)\n",
    "                    titles.append(clean_title)\n",
    "            return titles[:k]\n",
    "        except Exception:\n",
    "            # Very loose fallback: split by commas and clean each part\n",
    "            parts = [p.strip() for p in m2.group(1).split(\",\")]\n",
    "            titles = []\n",
    "            for part in parts:\n",
    "                if part.strip():\n",
    "                    # Clean quotes and apply genre removal\n",
    "                    clean_part = part.strip('\"\\'').strip()\n",
    "                    clean_title = _norm_title(clean_part)\n",
    "                    if clean_title:\n",
    "                        titles.append(clean_title)\n",
    "            return titles[:k]\n",
    "\n",
    "def _from_numbered_list(response: str, k=MAX_K):\n",
    "    \"\"\"\n",
    "    Parse Template C (numbered list) robustly:\n",
    "    - Start after the first line containing 'recommendations'\n",
    "    - Accept 1) or 1. prefixes\n",
    "    - Strip genre tails after -, – or —\n",
    "    - Handle ASCII and smart quotes\n",
    "    \"\"\"\n",
    "    text = response.replace(\"\\\\n\", \"\\n\")\n",
    "    lines = [ln.rstrip() for ln in text.splitlines()]\n",
    "\n",
    "    # Start AFTER the first line that mentions 'recommendations'\n",
    "    start = 0\n",
    "    for i, ln in enumerate(lines):\n",
    "        if \"recommendations\" in ln.lower():\n",
    "            start = i + 1\n",
    "            break\n",
    "\n",
    "    titles = []\n",
    "    for ln in lines[start:]:\n",
    "        mnum = RE_NUMBERED_LINE.match(ln)  # r'^\\s*\\d+[.)]\\s+(.*)$'\n",
    "        if not mnum:\n",
    "            continue\n",
    "\n",
    "        rest = mnum.group(1).strip()\n",
    "\n",
    "        # Cut off any trailing genre / notes after a dash, en dash, or em dash\n",
    "        rest = RE_DASH_SPLIT.split(rest)[0].strip(\" -–—\\t\")\n",
    "\n",
    "        # Strip smart/ASCII quotes around the title portion\n",
    "        rest = RE_SMART_QUOTES.sub('', rest)\n",
    "        rest = RE_WS_COLLAPSE.sub(' ', rest)\n",
    "\n",
    "        # If ends with (YYYY), normalize to \"Title (YYYY)\"\n",
    "        myear = re.search(r'\\((\\d{4})\\)\\s*$', rest)\n",
    "        if myear:\n",
    "            year = myear.group(1)\n",
    "            title = re.sub(r'\\s*\\(\\d{4}\\)\\s*$', '', rest)\n",
    "            title = RE_SMART_QUOTES.sub('', title).strip()\n",
    "            norm = _norm_title(f\"{title} ({year})\")\n",
    "        else:\n",
    "            norm = _norm_title(rest)\n",
    "\n",
    "        if norm:\n",
    "            titles.append(norm)\n",
    "            if len(titles) >= k:\n",
    "                break\n",
    "\n",
    "    return titles[:k]\n",
    "\n",
    "\n",
    "\n",
    "def _extract_from_quoted_strings(text: str, k=MAX_K):\n",
    "    \"\"\"\n",
    "    Extract movie titles from quoted strings, handling genres.\n",
    "    This is a fallback when JSON parsing fails.\n",
    "    \"\"\"\n",
    "    # Look for quoted strings that look like movie titles\n",
    "    # Pattern: \"Movie Title (Year)\" or \"Movie Title (Year) - Genre\"\n",
    "    movie_pattern = r'\"([^\"]*\\(\\d{4}\\)[^\"]*)\"'\n",
    "    matches = re.findall(movie_pattern, text)\n",
    "    \n",
    "    titles = []\n",
    "    for match in matches:\n",
    "        clean_title = _norm_title(match)\n",
    "        if clean_title and clean_title not in titles:\n",
    "            titles.append(clean_title)\n",
    "            if len(titles) >= k:\n",
    "                break\n",
    "    \n",
    "    return titles[:k]\n",
    "\n",
    "def extract_topk(response: str, k=MAX_K):\n",
    "    \"\"\"\n",
    "    Unified extractor with ordered fallbacks:\n",
    "    1) strict JSON object\n",
    "    2) embedded JSON-ish block\n",
    "    3) numbered list after 'recommendations'\n",
    "    4) quoted strings extraction\n",
    "    Normalizes, dedupes, and returns up to k titles.\n",
    "    \"\"\"\n",
    "    if not isinstance(response, str) or not response.strip():\n",
    "        return []\n",
    "\n",
    "    # 1) Pure JSON object\n",
    "    titles = _from_json_object(response, k)\n",
    "    if len(titles) >= k:\n",
    "        return _dedupe_preserve_order(titles)[:k]\n",
    "\n",
    "    # 2) Embedded JSON-ish\n",
    "    if not titles:\n",
    "        titles = _from_embedded_json(response, k)\n",
    "        if len(titles) >= k:\n",
    "            return _dedupe_preserve_order(titles)[:k]\n",
    "\n",
    "    # 3) Numbered list (Template C)\n",
    "    if not titles or len(titles) < k:\n",
    "        t2 = _from_numbered_list(response, k)\n",
    "        titles.extend([x for x in t2 if x])\n",
    "\n",
    "    # 4) Quoted strings extraction (fallback)\n",
    "    if not titles or len(titles) < k:\n",
    "        t3 = _extract_from_quoted_strings(response, k)\n",
    "        titles.extend([x for x in t3 if x])\n",
    "\n",
    "    # Normalize & dedupe once at the end\n",
    "    titles = _dedupe_preserve_order([_norm_title(t) for t in titles if t])\n",
    "    return titles[:k]\n",
    "\n",
    "# ── Main: read, extract, build DataFrame ──\n",
    "rows = []\n",
    "with FILE_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Parsing recommendations\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        recs = extract_topk(obj.get(\"response\", \"\"), k=MAX_K)\n",
    "\n",
    "        rows.append({\n",
    "            \"user_id\": obj.get(\"user_id\"),\n",
    "            \"template_set\": obj.get(\"template_set\"),\n",
    "            \"style\": obj.get(\"style\"),\n",
    "            \"recommended_movies\": recs\n",
    "        })\n",
    "\n",
    "df_greedy_recs = pd.DataFrame(rows)\n",
    "\n",
    "# Expand to movie_1 … movie_10\n",
    "for i in range(MAX_K):\n",
    "    df_greedy_recs[f\"movie_{i+1}\"] = df_greedy_recs[\"recommended_movies\"].apply(\n",
    "        lambda x, i=i: x[i] if isinstance(x, list) and len(x) > i else None\n",
    "    )\n",
    "\n",
    "print(df_greedy_recs.head(2))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing recommendations: 1200it [00:00, 3185.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id template_set         style  \\\n",
      "0       10            B     zero_shot   \n",
      "1       10            A  few_shot_cot   \n",
      "\n",
      "                                  recommended_movies               movie_1  \\\n",
      "0  [The Godfather (1972), Casablanca (1942), The ...  The Godfather (1972)   \n",
      "1  [Casablanca (1942), Rear Window (1954), Chinat...     Casablanca (1942)   \n",
      "\n",
      "              movie_2                          movie_3               movie_4  \\\n",
      "0   Casablanca (1942)  The Shawshank Redemption (1994)   Pulp Fiction (1994)   \n",
      "1  Rear Window (1954)                 Chinatown (1974)  The Godfather (1972)   \n",
      "\n",
      "                  movie_5                    movie_6  \\\n",
      "0  The Dark Knight (2008)    Schindler's List (1993)   \n",
      "1    The Third Man (1949)  The Maltese Falcon (1941)   \n",
      "\n",
      "                                 movie_7                          movie_8  \\\n",
      "0                       Inception (2010)                Fight Club (1999)   \n",
      "1  The Good, the Bad and the Ugly (1966)  The Shawshank Redemption (1994)   \n",
      "\n",
      "                           movie_9             movie_10  \n",
      "0              Forrest Gump (1994)    The Matrix (1999)  \n",
      "1  The Silence of the Lambs (1991)  The Graduate (1967)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "2bc2cbe098caeb56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T23:22:06.278186Z",
     "start_time": "2025-10-24T23:22:06.260603Z"
    }
   },
   "source": [
    "df_greedy_recs.head(1800)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      user_id template_set          style  \\\n",
       "0          10            B      zero_shot   \n",
       "1          10            A   few_shot_cot   \n",
       "2          10            A       few_shot   \n",
       "3          10            B   few_shot_cot   \n",
       "4          10            B       few_shot   \n",
       "...       ...          ...            ...   \n",
       "1195      943            C       few_shot   \n",
       "1196      943            C   few_shot_cot   \n",
       "1197      943            B  zero_shot_cot   \n",
       "1198      943            B   few_shot_cot   \n",
       "1199      943            C  zero_shot_cot   \n",
       "\n",
       "                                     recommended_movies               movie_1  \\\n",
       "0     [The Godfather (1972), Casablanca (1942), The ...  The Godfather (1972)   \n",
       "1     [Casablanca (1942), Rear Window (1954), Chinat...     Casablanca (1942)   \n",
       "2     [Casablanca (1942), Rear Window (1954), Chinat...     Casablanca (1942)   \n",
       "3     [Casablanca (1942), Rear Window (1954), Chinat...     Casablanca (1942)   \n",
       "4     [Casablanca (1942), Rear Window (1954), Chinat...     Casablanca (1942)   \n",
       "...                                                 ...                   ...   \n",
       "1195  [Die Hard (1988), Lethal Weapon (1987), Ghostb...       Die Hard (1988)   \n",
       "1196  [Die Hard (1988), Lethal Weapon (1987), Ghostb...       Die Hard (1988)   \n",
       "1197                                                 []                  None   \n",
       "1198  [Die Hard (1988), Lethal Weapon (1987), Jurass...       Die Hard (1988)   \n",
       "1199  [Die Hard (1988), The Matrix (1999), Jurassic ...       Die Hard (1988)   \n",
       "\n",
       "                   movie_2                          movie_3  \\\n",
       "0        Casablanca (1942)  The Shawshank Redemption (1994)   \n",
       "1       Rear Window (1954)                 Chinatown (1974)   \n",
       "2       Rear Window (1954)                 Chinatown (1974)   \n",
       "3       Rear Window (1954)                 Chinatown (1974)   \n",
       "4       Rear Window (1954)                 Chinatown (1974)   \n",
       "...                    ...                              ...   \n",
       "1195  Lethal Weapon (1987)              Ghostbusters (1984)   \n",
       "1196  Lethal Weapon (1987)              Ghostbusters (1984)   \n",
       "1197                  None                             None   \n",
       "1198  Lethal Weapon (1987)             Jurassic Park (1993)   \n",
       "1199     The Matrix (1999)             Jurassic Park (1993)   \n",
       "\n",
       "                                movie_4                            movie_5  \\\n",
       "0                   Pulp Fiction (1994)             The Dark Knight (2008)   \n",
       "1                  The Godfather (1972)               The Third Man (1949)   \n",
       "2                  The Godfather (1972)               The Third Man (1949)   \n",
       "3                  The Godfather (1972)               The Third Man (1949)   \n",
       "4                  The Godfather (1972)               The Third Man (1949)   \n",
       "...                                 ...                                ...   \n",
       "1195          Back to the Future (1985)  Terminator 2: Judgment Day (1991)   \n",
       "1196           The Fifth Element (1997)                    The Rock (1996)   \n",
       "1197                               None                               None   \n",
       "1198  Terminator 2: Judgment Day (1991)          Back to the Future (1985)   \n",
       "1199              The Terminator (1984)          Back to the Future (1985)   \n",
       "\n",
       "                        movie_6                                movie_7  \\\n",
       "0       Schindler's List (1993)                       Inception (2010)   \n",
       "1     The Maltese Falcon (1941)  The Good, the Bad and the Ugly (1966)   \n",
       "2     The Maltese Falcon (1941)                   The Big Sleep (1946)   \n",
       "3     The Maltese Falcon (1941)                   The Big Sleep (1946)   \n",
       "4     The Maltese Falcon (1941)                    The Graduate (1967)   \n",
       "...                         ...                                    ...   \n",
       "1195            Predator (1987)                          Aliens (1986)   \n",
       "1196   Beverly Hills Cop (1984)                  The Terminator (1984)   \n",
       "1197                       None                                   None   \n",
       "1198        Ghostbusters (1984)                          Aliens (1986)   \n",
       "1199        Pulp Fiction (1994)        The Shawshank Redemption (1994)   \n",
       "\n",
       "                                        movie_8  \\\n",
       "0                             Fight Club (1999)   \n",
       "1               The Shawshank Redemption (1994)   \n",
       "2                       Double Indemnity (1944)   \n",
       "3     Butch Cassidy and the Sundance Kid (1969)   \n",
       "4                          The Big Sleep (1946)   \n",
       "...                                         ...   \n",
       "1195                   Beverly Hills Cop (1984)   \n",
       "1196                  Back to the Future (1985)   \n",
       "1197                                       None   \n",
       "1198                        Pulp Fiction (1994)   \n",
       "1199                        Ghostbusters (1984)   \n",
       "\n",
       "                              movie_9  \\\n",
       "0                 Forrest Gump (1994)   \n",
       "1     The Silence of the Lambs (1991)   \n",
       "2                 Sunset Blvd. (1950)   \n",
       "3                 The Graduate (1967)   \n",
       "4        The French Connection (1971)   \n",
       "...                               ...   \n",
       "1195        Mad Max: Fury Road (2015)   \n",
       "1196                  Predator (1987)   \n",
       "1197                             None   \n",
       "1198               Matrix, The (1999)   \n",
       "1199                    Aliens (1986)   \n",
       "\n",
       "                                       movie_10  \n",
       "0                             The Matrix (1999)  \n",
       "1                           The Graduate (1967)  \n",
       "2         The Good, the Bad and the Ugly (1966)  \n",
       "3                          The Apartment (1960)  \n",
       "4     Butch Cassidy and the Sundance Kid (1969)  \n",
       "...                                         ...  \n",
       "1195                          The Matrix (1999)  \n",
       "1196                            The Mask (1994)  \n",
       "1197                                       None  \n",
       "1198                               Fargo (1996)  \n",
       "1199            The Silence of the Lambs (1991)  \n",
       "\n",
       "[1200 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>template_set</th>\n",
       "      <th>style</th>\n",
       "      <th>recommended_movies</th>\n",
       "      <th>movie_1</th>\n",
       "      <th>movie_2</th>\n",
       "      <th>movie_3</th>\n",
       "      <th>movie_4</th>\n",
       "      <th>movie_5</th>\n",
       "      <th>movie_6</th>\n",
       "      <th>movie_7</th>\n",
       "      <th>movie_8</th>\n",
       "      <th>movie_9</th>\n",
       "      <th>movie_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>[The Godfather (1972), Casablanca (1942), The ...</td>\n",
       "      <td>The Godfather (1972)</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>The Shawshank Redemption (1994)</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>The Dark Knight (2008)</td>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>Inception (2010)</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>The Matrix (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>[Casablanca (1942), Rear Window (1954), Chinat...</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>Rear Window (1954)</td>\n",
       "      <td>Chinatown (1974)</td>\n",
       "      <td>The Godfather (1972)</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>The Maltese Falcon (1941)</td>\n",
       "      <td>The Good, the Bad and the Ugly (1966)</td>\n",
       "      <td>The Shawshank Redemption (1994)</td>\n",
       "      <td>The Silence of the Lambs (1991)</td>\n",
       "      <td>The Graduate (1967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>[Casablanca (1942), Rear Window (1954), Chinat...</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>Rear Window (1954)</td>\n",
       "      <td>Chinatown (1974)</td>\n",
       "      <td>The Godfather (1972)</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>The Maltese Falcon (1941)</td>\n",
       "      <td>The Big Sleep (1946)</td>\n",
       "      <td>Double Indemnity (1944)</td>\n",
       "      <td>Sunset Blvd. (1950)</td>\n",
       "      <td>The Good, the Bad and the Ugly (1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>[Casablanca (1942), Rear Window (1954), Chinat...</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>Rear Window (1954)</td>\n",
       "      <td>Chinatown (1974)</td>\n",
       "      <td>The Godfather (1972)</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>The Maltese Falcon (1941)</td>\n",
       "      <td>The Big Sleep (1946)</td>\n",
       "      <td>Butch Cassidy and the Sundance Kid (1969)</td>\n",
       "      <td>The Graduate (1967)</td>\n",
       "      <td>The Apartment (1960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>[Casablanca (1942), Rear Window (1954), Chinat...</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>Rear Window (1954)</td>\n",
       "      <td>Chinatown (1974)</td>\n",
       "      <td>The Godfather (1972)</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>The Maltese Falcon (1941)</td>\n",
       "      <td>The Graduate (1967)</td>\n",
       "      <td>The Big Sleep (1946)</td>\n",
       "      <td>The French Connection (1971)</td>\n",
       "      <td>Butch Cassidy and the Sundance Kid (1969)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>943</td>\n",
       "      <td>C</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>[Die Hard (1988), Lethal Weapon (1987), Ghostb...</td>\n",
       "      <td>Die Hard (1988)</td>\n",
       "      <td>Lethal Weapon (1987)</td>\n",
       "      <td>Ghostbusters (1984)</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>Predator (1987)</td>\n",
       "      <td>Aliens (1986)</td>\n",
       "      <td>Beverly Hills Cop (1984)</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>The Matrix (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>943</td>\n",
       "      <td>C</td>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>[Die Hard (1988), Lethal Weapon (1987), Ghostb...</td>\n",
       "      <td>Die Hard (1988)</td>\n",
       "      <td>Lethal Weapon (1987)</td>\n",
       "      <td>Ghostbusters (1984)</td>\n",
       "      <td>The Fifth Element (1997)</td>\n",
       "      <td>The Rock (1996)</td>\n",
       "      <td>Beverly Hills Cop (1984)</td>\n",
       "      <td>The Terminator (1984)</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Predator (1987)</td>\n",
       "      <td>The Mask (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>943</td>\n",
       "      <td>B</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>943</td>\n",
       "      <td>B</td>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>[Die Hard (1988), Lethal Weapon (1987), Jurass...</td>\n",
       "      <td>Die Hard (1988)</td>\n",
       "      <td>Lethal Weapon (1987)</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Ghostbusters (1984)</td>\n",
       "      <td>Aliens (1986)</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>943</td>\n",
       "      <td>C</td>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>[Die Hard (1988), The Matrix (1999), Jurassic ...</td>\n",
       "      <td>Die Hard (1988)</td>\n",
       "      <td>The Matrix (1999)</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>The Terminator (1984)</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>The Shawshank Redemption (1994)</td>\n",
       "      <td>Ghostbusters (1984)</td>\n",
       "      <td>Aliens (1986)</td>\n",
       "      <td>The Silence of the Lambs (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "7936a724bebdeaf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T23:17:50.392400Z",
     "start_time": "2025-10-24T23:17:50.364117Z"
    }
   },
   "source": [
    "df_greedy_recs.to_csv(\"greedy_results_normal/df_template_gpt_4o_mini.csv\")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45eb5d32f34b4b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T04:20:56.696256Z",
     "start_time": "2025-10-12T04:20:56.685331Z"
    }
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# Inputs\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "target_user_id = 378\n",
    "target_template_set = \"B\"\n",
    "target_prompt_type = \"few_shot\"  # or use 'style' depending on your column\n",
    "recommended_list = [\n",
    "  \"Goodfellas (1990)\",\n",
    "    \"The Silence of the Lambs (1991)\",\n",
    "    \"Terminator 2: Judgment Day (1991)\",\n",
    "    \"Jurassic Park (1993)\",\n",
    "    \"Pulp Fiction (1994)\",\n",
    "    \"Forrest Gump (1994)\",\n",
    "    \"The Shawshank Redemption (1994)\",\n",
    "    \"Pulp Fiction (1994)\",\n",
    "    \"Se7en (1995)\",\n",
    "    \"The English Patient (1996)\"\n",
    "]\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Row Mask: Filter the exact row you want to assign\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "row_mask = (\n",
    "    (df_greedy_recs['user_id'] == target_user_id) &\n",
    "    (df_greedy_recs['template_set'] == target_template_set) &\n",
    "    (df_greedy_recs['style'] == target_prompt_type)  # or 'prompt_type' if applicable\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Assign the full list to the 'recommended_movies' column\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "df_greedy_recs.loc[row_mask, 'recommended_movies'] = \\\n",
    "    df_greedy_recs.loc[row_mask].apply(lambda _: recommended_list, axis=1)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# Optionally expand into movie_1 to movie_10\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "for i in range(10):\n",
    "    col = f\"movie_{i+1}\"\n",
    "    df_greedy_recs.loc[row_mask, col] = recommended_list[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75bcf0cf8cd3beb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T00:59:17.411302Z",
     "start_time": "2025-10-19T00:59:17.358812Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col_names_for_user_ratings = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "col_names_for_users = ['user_id' , 'age' , 'gender' , 'occupation' ,'zip code']\n",
    "\n",
    "\n",
    "df_user_ratings = pd.read_csv(\n",
    "    'data/ml-100k/u.data',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=col_names_for_user_ratings,\n",
    "    encoding='latin-1'\n",
    ")\n",
    "\n",
    "# Step 1: Count interactions\n",
    "movie_interactions = (\n",
    "    df_user_ratings\n",
    "    .groupby('movie_id')\n",
    "    .size()\n",
    "    .reset_index(name='interaction_count')\n",
    "    .sort_values(by='interaction_count', ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aafab6d3b8c0bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T00:59:20.686133Z",
     "start_time": "2025-10-19T00:59:20.615947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, 364 users remain.\n",
      "Train set: 59469 rows\n",
      "Test set:  15053 rows\n",
      "Minimum number of interactions among kept users: 100\n",
      "Number of users with <= 100 interactions: 579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_user_ratings[\"date\"] = pd.to_datetime(df_user_ratings[\"timestamp\"], unit='s')\n",
    "\n",
    "# Count interactions per user\n",
    "interaction_counts = df_user_ratings.groupby('user_id').size()\n",
    "\n",
    "# Filter users with more than 60 interactions (strictly > 100)\n",
    "valid_users = interaction_counts[interaction_counts >= 100].index\n",
    "\n",
    "# Apply the filter\n",
    "df_filtered_user_ratings = df_user_ratings[df_user_ratings['user_id'].isin(valid_users)].copy()\n",
    "\n",
    "# Sort interactions chronologically per user\n",
    "df_filtered_user_ratings.sort_values(['user_id', 'date'], inplace=True)\n",
    "\n",
    "# Split each user's history: 80% train, 20% test\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for uid, user_df in df_filtered_user_ratings.groupby('user_id', sort=False):\n",
    "    n = len(user_df)\n",
    "    split_pt = int(n * 0.8)\n",
    "    train_list.append(user_df.iloc[:split_pt])\n",
    "    test_list.append(user_df.iloc[split_pt:])\n",
    "\n",
    "# Combine all user splits\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "# Output some stats\n",
    "print(f\"After filtering, {len(valid_users)} users remain.\")\n",
    "print(f\"Train set: {len(train_df)} rows\")\n",
    "print(f\"Test set:  {len(test_df)} rows\")\n",
    "\n",
    "print(f\"Minimum number of interactions among kept users: {interaction_counts[valid_users].min()}\")\n",
    "print(f\"Number of users with <= 100 interactions: {(interaction_counts < 100).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eea5fc2da2660ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T00:59:25.480133Z",
     "start_time": "2025-10-19T00:59:25.474765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked users: [1, 92, 433]\n",
      "Remaining valid users: [5, 6, 7, 10, 11, 13, 15, 16, 18, 21, 22, 23, 26, 38, 42, 43, 44, 49, 56, 57, 58, 59, 60, 62, 64, 70, 72, 82, 83, 85, 87, 90, 94, 95, 99, 102, 104, 109, 110, 116, 119, 125, 128, 130, 141, 144, 145, 151, 152, 158, 159, 160, 174, 177, 178, 181, 184, 188, 189, 193, 194, 197, 198, 200, 201, 207, 210, 213, 214, 216, 221, 222, 223, 224, 230, 233, 234, 236, 239, 244, 246, 249, 250, 254, 256, 262, 263, 264, 267, 268, 269, 270, 271, 276, 279, 280, 286, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 303, 305, 307, 308, 311, 312, 313, 314, 318, 320, 321, 325, 326, 327, 328, 330, 332, 334, 336, 339, 342, 343, 344, 345, 346, 347, 354, 360, 361, 363, 373, 374, 378, 379, 380, 381, 385, 387, 389, 391, 392, 393, 394, 397, 398, 399, 401, 405, 406, 407, 409, 416, 417, 425, 426, 429, 435, 436, 437, 442, 445, 447, 450, 452, 453, 454, 455, 456, 457, 458, 459, 463, 466, 468, 472, 474, 478, 479, 484, 486, 487, 488, 489, 493, 495, 496, 497, 498, 499, 500, 503, 504, 505, 506, 514, 521, 523, 524, 527, 532, 533, 535, 536, 537, 541, 542, 543, 545, 548, 551, 553, 554, 560, 561, 566, 567, 577, 586, 588, 592, 593, 601, 606, 608, 615, 617, 618, 620, 621, 622, 624, 625, 627, 629, 630, 632, 634, 637, 639, 640, 642, 643, 645, 648, 650, 653, 654, 655, 659, 660, 661, 663, 664, 665, 666, 669, 671, 682, 690, 693, 694, 697, 698, 699, 705, 707, 708, 709, 711, 712, 715, 716, 721, 727, 733, 738, 741, 747, 748, 749, 751, 756, 757, 758, 763, 764, 766, 773, 774, 776, 782, 786, 788, 790, 795, 796, 798, 804, 805, 806, 807, 815, 823, 825, 826, 828, 830, 833, 835, 840, 843, 846, 847, 848, 851, 854, 862, 863, 864, 868, 870, 871, 878, 880, 881, 882, 883, 885, 886, 887, 889, 890, 892, 894, 896, 897, 899, 901, 903, 907, 913, 916, 918, 919, 921, 922, 927, 932, 933, 934, 936, 938, 940, 943]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Turn your valid_users (Index or list) into a plain list:\n",
    "valid_users_list = list(valid_users)\n",
    "\n",
    "\n",
    "three_picked = [1,92,433]\n",
    "print(\"Picked users:\", three_picked)\n",
    "remaining_valid_users_list = [u for u in valid_users_list if u not in three_picked]\n",
    "print(\"Remaining valid users:\", remaining_valid_users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0f7add2a15cea30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T00:59:30.553333Z",
     "start_time": "2025-10-19T00:59:29.992864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_filtered_user_data shape: (362, 4)\n",
      "df_filtered_example_user_data shape: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 7) Sampling helper ---\n",
    "def select_sample(user_ids, k=10, random_state=42):\n",
    "    \"\"\"\n",
    "    For each user:\n",
    "      - ground_truth_total_itemIds: all items (train+test)\n",
    "      - ground_truth_test_itemIds: only test items\n",
    "      - sample_random: up to k random items from their train history, ordered chronologically\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    records = []\n",
    "\n",
    "    for uid in user_ids:\n",
    "        user_all = df_filtered_user_ratings.loc[df_filtered_user_ratings.user_id == uid]\n",
    "        total_items = user_all['movie_id'].tolist()\n",
    "\n",
    "        user_test = test_df.loc[test_df.user_id == uid]\n",
    "        test_items = user_test['movie_id'].tolist()\n",
    "\n",
    "        user_train = train_df.loc[train_df.user_id == uid].copy()\n",
    "\n",
    "        if user_train.empty:\n",
    "            # No train data — keep sample empty but still record ground truth\n",
    "            random_sample = []\n",
    "        else:\n",
    "            # sample up to k rows (no replacement)\n",
    "            n_pick = min(k, len(user_train))\n",
    "            # Use pandas sample with a deterministic seed per user for reproducibility\n",
    "            # Seed is derived from (random_state, uid) so different users differ but are reproducible\n",
    "            seed = (hash((random_state, int(uid))) % (2**32 - 1))\n",
    "            sample_df = (\n",
    "                user_train\n",
    "                .sample(n=n_pick, replace=False, random_state=seed)\n",
    "                .sort_values('date', ascending=True)\n",
    "            )\n",
    "            # keep only movie_id and rating\n",
    "            keep_cols = [c for c in ['movie_id', 'rating'] if c in sample_df.columns]\n",
    "            random_sample = sample_df[keep_cols].values.tolist()\n",
    "\n",
    "        records.append({\n",
    "            'user_id': uid,\n",
    "            'ground_truth_total_itemIds': total_items,\n",
    "            'ground_truth_test_itemIds': test_items,\n",
    "            'sample_random': random_sample\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- 8) Build the two DataFrames ---\n",
    "df_filtered_user_data = select_sample(remaining_valid_users_list)\n",
    "df_filtered_example_user_data = select_sample(three_picked)\n",
    "\n",
    "print(\"df_filtered_user_data shape:\", df_filtered_user_data.shape)\n",
    "print(\"df_filtered_example_user_data shape:\", df_filtered_example_user_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "829c8da9d6d3db94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T00:59:33.809133Z",
     "start_time": "2025-10-19T00:59:33.766337Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movies=pd.read_csv(\"data/final_movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0d67033358308a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T00:59:36.724818Z",
     "start_time": "2025-10-19T00:59:36.642102Z"
    }
   },
   "outputs": [],
   "source": [
    "df_extra_movies=pd.read_csv(\"data/movies.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "503099f75a5a1068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:08:59.888260Z",
     "start_time": "2025-10-19T01:08:59.875054Z"
    }
   },
   "outputs": [],
   "source": [
    "df_greedy_recs = pd.read_csv(\"data/gpt_4o_mini/results_normal/df_template_gpt_40_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "61d2ef3a2ab84972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:10:12.838597Z",
     "start_time": "2025-10-19T01:09:02.541715Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching all movie titles: 100%|██████████| 10/10 [01:10<00:00,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unmatched titles: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Cleaning Function ===\n",
    "RE_YEAR = re.compile(r\"\\(\\d{4}\\)\")\n",
    "RE_QUOTES = re.compile(r'^\"+|\"+$')\n",
    "RE_SPACES = re.compile(r'\\s+')\n",
    "RE_TRAIL_GENRES = re.compile(r'\\s*[-–—]\\s*.*$')\n",
    "RE_SPECIAL = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
    "\n",
    "def clean_title_for_matching(title):\n",
    "    \"\"\"Normalize movie titles by removing punctuation, years, colons, etc., without truncation.\"\"\"\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "    title = title.replace(\":\", \"\")  #  FIX: Remove colon instead of truncating after it\n",
    "    title = RE_TRAIL_GENRES.sub(\"\", title)\n",
    "    title = RE_YEAR.sub(\"\", title)\n",
    "    title = RE_QUOTES.sub(\"\", title)\n",
    "    title = RE_SPECIAL.sub(\"\", title)\n",
    "    return RE_SPACES.sub(\" \", title).strip().lower()\n",
    "\n",
    "# === Matching Function ===\n",
    "def match_to_catalogs(title, df_movies, df_extra_movies, cutoff=0.8):\n",
    "    \"\"\"\n",
    "    Try to match a given title to df_movies first, then df_extra_movies.\n",
    "    If match found, return the official catalog title. Otherwise return None.\n",
    "    \"\"\"\n",
    "    if not isinstance(title, str) or not title.strip():\n",
    "        return None\n",
    "\n",
    "    title_cleaned = clean_title_for_matching(title)\n",
    "\n",
    "    # --- Step 1: Primary catalog (df_movies) ---\n",
    "    best_primary = process.extractOne(\n",
    "        title_cleaned,\n",
    "        df_movies[\"clean_title\"],\n",
    "        scorer=fuzz.token_sort_ratio,\n",
    "        score_cutoff=cutoff * 100\n",
    "    )\n",
    "    if best_primary is not None:\n",
    "        matched_title = df_movies.loc[\n",
    "            df_movies[\"clean_title\"] == best_primary[0], \"title\"\n",
    "        ].iloc[0]\n",
    "        return matched_title\n",
    "\n",
    "    # --- Step 2: Secondary catalog (df_extra_movies) ---\n",
    "    best_extra = process.extractOne(\n",
    "        title_cleaned,\n",
    "        df_extra_movies[\"clean_title\"],\n",
    "        scorer=fuzz.token_sort_ratio,\n",
    "        score_cutoff=cutoff * 100\n",
    "    )\n",
    "    if best_extra is not None:\n",
    "        matched_title = df_extra_movies.loc[\n",
    "            df_extra_movies[\"clean_title\"] == best_extra[0], \"title\"\n",
    "        ].iloc[0]\n",
    "        return matched_title\n",
    "\n",
    "    # --- Step 3: No match found ---\n",
    "    return None\n",
    "\n",
    "# === Main Replacement Function ===\n",
    "def replace_titles_with_matched(df_greedy_recs, df_movies, df_extra_movies, cutoff=0.8):\n",
    "    \"\"\"\n",
    "    Replace each movie_i column in df_greedy_recs with the matched title from df_movies or df_extra_movies.\n",
    "    If not matched, replace with None.\n",
    "    \"\"\"\n",
    "    # Prepare both catalogs with cleaned titles\n",
    "    df_movies = df_movies.copy()\n",
    "    df_extra_movies = df_extra_movies.copy()\n",
    "    df_movies[\"clean_title\"] = df_movies[\"title\"].apply(clean_title_for_matching)\n",
    "    df_extra_movies[\"clean_title\"] = df_extra_movies[\"title\"].apply(clean_title_for_matching)\n",
    "\n",
    "    # Copy df_greedy_recs to avoid modifying original\n",
    "    df_replaced = df_greedy_recs.copy()\n",
    "\n",
    "    # Iterate through each recommendation column\n",
    "    movie_cols = [f\"movie_{i}\" for i in range(1, 11)]\n",
    "    for col in tqdm(movie_cols, desc=\"Matching all movie titles\"):\n",
    "        df_replaced[col] = df_replaced[col].apply(\n",
    "            lambda x: match_to_catalogs(x, df_movies, df_extra_movies, cutoff)\n",
    "        )\n",
    "\n",
    "    return df_replaced\n",
    "\n",
    "# === Unmatched Movie Extractor ===\n",
    "def get_unmatched_titles(df_original, df_replaced):\n",
    "    movie_cols = [f\"movie_{i}\" for i in range(1, 11)]\n",
    "    unmatched_titles = []\n",
    "\n",
    "    for col in movie_cols:\n",
    "        original = df_original[col]\n",
    "        replaced = df_replaced[col]\n",
    "        unmatched = original[replaced.isna()]\n",
    "        unmatched_titles.extend(unmatched.tolist())\n",
    "\n",
    "    unmatched_unique = pd.Series(unmatched_titles).dropna().unique().tolist()\n",
    "    return unmatched_unique\n",
    "\n",
    "# === Example Usage ===\n",
    "# Make sure df_greedy_recs, df_movies, df_extra_movies are defined above this call\n",
    "df_replaced = replace_titles_with_matched(df_greedy_recs, df_movies, df_extra_movies, cutoff=0.8)\n",
    "\n",
    "# Get unmatched titles\n",
    "unmatched_titles = get_unmatched_titles(df_greedy_recs, df_replaced)\n",
    "\n",
    "# Display result\n",
    "print(f\"\\nTotal unmatched titles: {len(unmatched_titles)}\")\n",
    "for title in unmatched_titles:\n",
    "    print(\"-\", title)\n",
    "\n",
    "# Optional: Save unmatched to CSV\n",
    "# pd.Series(unmatched_titles, name=\"unmatched_titles\").to_csv(\"unmatched_titles.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7e10f6d3b5d773c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:10:15.839437Z",
     "start_time": "2025-10-19T01:10:15.826048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "596445906dd757d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:10:19.324713Z",
     "start_time": "2025-10-19T01:10:19.300852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            style template_set  total_titles_checked  matched_titles  \\\n",
      "0        few_shot            A                  1000            1000   \n",
      "1        few_shot            B                  1000            1000   \n",
      "2        few_shot            C                  1000            1000   \n",
      "3    few_shot_cot            A                  1000            1000   \n",
      "4    few_shot_cot            B                  1000            1000   \n",
      "5    few_shot_cot            C                  1000            1000   \n",
      "6       zero_shot            A                  1000            1000   \n",
      "7       zero_shot            B                  1000            1000   \n",
      "8       zero_shot            C                  1000            1000   \n",
      "9   zero_shot_cot            A                  1000            1000   \n",
      "10  zero_shot_cot            B                  1000            1000   \n",
      "11  zero_shot_cot            C                  1000            1000   \n",
      "\n",
      "    unmatched_titles  match_rate_%  \n",
      "0                  0         100.0  \n",
      "1                  0         100.0  \n",
      "2                  0         100.0  \n",
      "3                  0         100.0  \n",
      "4                  0         100.0  \n",
      "5                  0         100.0  \n",
      "6                  0         100.0  \n",
      "7                  0         100.0  \n",
      "8                  0         100.0  \n",
      "9                  0         100.0  \n",
      "10                 0         100.0  \n",
      "11                 0         100.0  \n"
     ]
    }
   ],
   "source": [
    "def summarize_unmatched_titles(df_replaced):\n",
    "    \"\"\"\n",
    "    Summarize how many None (unmatched) titles remain in df_replaced,\n",
    "    grouped by (style, template_set).\n",
    "    \"\"\"\n",
    "    movie_cols = [f\"movie_{i}\" for i in range(1, 11)]\n",
    "    summary_rows = []\n",
    "\n",
    "    for (style, template), group in df_replaced.groupby([\"style\", \"template_set\"]):\n",
    "        total_titles = group[movie_cols].size               # total number of cells (users × 10)\n",
    "        none_count = group[movie_cols].isna().sum().sum()   # total number of None (unmatched)\n",
    "        matched_count = total_titles - none_count\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"style\": style,\n",
    "            \"template_set\": template,\n",
    "            \"total_titles_checked\": total_titles,\n",
    "            \"matched_titles\": matched_count,\n",
    "            \"unmatched_titles\": none_count,\n",
    "            \"match_rate_%\": round(100 * matched_count / total_titles, 2)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary_rows).sort_values(by=[\"style\", \"template_set\"]).reset_index(drop=True)\n",
    "\n",
    "# === Run the summary ===\n",
    "df_summary = summarize_unmatched_titles(df_replaced)\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9d0b4a348e00c969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:07:20.502213Z",
     "start_time": "2025-10-19T01:07:20.495170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   user_id             1200 non-null   int64 \n",
      " 1   template_set        1200 non-null   object\n",
      " 2   style               1200 non-null   object\n",
      " 3   recommended_movies  1200 non-null   object\n",
      " 4   movie_1             1200 non-null   object\n",
      " 5   movie_2             1200 non-null   object\n",
      " 6   movie_3             1200 non-null   object\n",
      " 7   movie_4             1200 non-null   object\n",
      " 8   movie_5             1200 non-null   object\n",
      " 9   movie_6             1200 non-null   object\n",
      " 10  movie_7             1200 non-null   object\n",
      " 11  movie_8             1200 non-null   object\n",
      " 12  movie_9             1200 non-null   object\n",
      " 13  movie_10            1200 non-null   object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 131.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_greedy_recs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9c71d57ccf567cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:10:46.609090Z",
     "start_time": "2025-10-19T01:10:22.688716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [00:23<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "\n",
    "# === RapidFuzz Matching ===\n",
    "def match_title_to_id(title, catalog_titles, title_to_id, cutoff=0.8):\n",
    "    \"\"\"Return movie_id if matched above cutoff; else None.\"\"\"\n",
    "    if not isinstance(title, str) or not title.strip():\n",
    "        return None\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for candidate in catalog_titles:\n",
    "        score = fuzz.token_sort_ratio(title, candidate) / 100\n",
    "        if score > best_score:\n",
    "            best_match = candidate\n",
    "            best_score = score\n",
    "    return title_to_id.get(best_match) if best_score >= cutoff else None\n",
    "\n",
    "\n",
    "# === Unmatched Title Clustering ===\n",
    "def cluster_unmatched_titles(unmatched_titles, cutoff=0.8):\n",
    "    \"\"\"\n",
    "    Group similar unmatched titles (>= cutoff similarity) using RapidFuzz.\n",
    "    Returns mapping {title: representative_title}.\n",
    "    \"\"\"\n",
    "    unmatched_titles = list(set([t for t in unmatched_titles if isinstance(t, str) and t.strip()]))\n",
    "    seen = set()\n",
    "    mapping = {}\n",
    "\n",
    "    for t in unmatched_titles:\n",
    "        if t in seen:\n",
    "            continue\n",
    "        mapping[t] = t\n",
    "        seen.add(t)\n",
    "        for other in unmatched_titles:\n",
    "            if other not in seen:\n",
    "                score = fuzz.token_sort_ratio(t, other) / 100\n",
    "                if score >= cutoff:\n",
    "                    mapping[other] = t\n",
    "                    seen.add(other)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# === Accuracy Metrics ===\n",
    "def hit_ratio_at_k(rec_ids, gt_ids, k=10):\n",
    "    return int(any(x in gt_ids for x in rec_ids[:k] if isinstance(x, int)))\n",
    "\n",
    "\n",
    "def precision_at_k(rec_ids, gt_ids, k=10):\n",
    "    topk = [x for x in rec_ids[:k] if isinstance(x, int)]\n",
    "    return len([x for x in topk if x in gt_ids]) / k\n",
    "\n",
    "\n",
    "def ndcg_at_k(rec_ids, gt_ids, k=10):\n",
    "    dcg = sum(1 / np.log2(i + 2) for i, x in enumerate(rec_ids[:k]) if isinstance(x, int) and x in gt_ids)\n",
    "    ideal_dcg = sum(1 / np.log2(i + 2) for i in range(min(len(gt_ids), k)))\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "\n",
    "# === Fairness/Diversity Metrics ===\n",
    "def gini_index(counts):\n",
    "    \"\"\"Gini coefficient of exposure inequality.\"\"\"\n",
    "    sorted_vals = np.sort(np.array(counts))\n",
    "    n = len(sorted_vals)\n",
    "    if n == 0 or sorted_vals.sum() == 0:\n",
    "        return 0.0\n",
    "    index = np.sum((2 * np.arange(1, n + 1) - n - 1) * sorted_vals)\n",
    "    return round(index / (n * sorted_vals.sum()), 4)\n",
    "\n",
    "\n",
    "def natural_entropy(counts):\n",
    "    \"\"\"Entropy of exposure diversity.\"\"\"\n",
    "    total = sum(counts)\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    p = np.array(counts) / total\n",
    "    return round(entropy(p, base=np.e), 4)\n",
    "\n",
    "\n",
    "# === Main Evaluation ===\n",
    "def evaluate_all_metrics(df_greedy_recs, df_movies, df_filtered_user_data, cutoff=0.8):\n",
    "    \"\"\"\n",
    "    Evaluate all metrics grouped by (style, template_set):\n",
    "    - Accuracy: HR@10, Precision@10, NDCG@10 (per user, averaged)\n",
    "    - Fairness/Diversity: Gini, Entropy (from exposure counts)\n",
    "    \"\"\"\n",
    "    catalog_titles = df_movies[\"title\"].tolist()\n",
    "    title_to_id = dict(zip(df_movies[\"title\"], df_movies[\"movie_id\"]))\n",
    "    gt_by_user = df_filtered_user_data.set_index(\"user_id\").to_dict(\"index\")\n",
    "\n",
    "    metrics_rows = []\n",
    "\n",
    "    for (style, template), group in tqdm(df_greedy_recs.groupby([\"style\", \"template_set\"]), desc=\"Evaluating\"):\n",
    "        per_user_recs = {}\n",
    "        unmatched_titles = []\n",
    "        all_recs = []\n",
    "\n",
    "        # === Step 1: Per-user matching (preserve order) ===\n",
    "        for _, row in group.iterrows():\n",
    "            uid = row[\"user_id\"]\n",
    "            rec_list = [row.get(f\"movie_{i}\", None) for i in range(1, 11)]\n",
    "            matched_list = []\n",
    "\n",
    "            for title in rec_list:\n",
    "                if title is None or (isinstance(title, float) and pd.isna(title)):\n",
    "                    matched_list.append(None)\n",
    "                    continue\n",
    "\n",
    "                mid = match_title_to_id(title, catalog_titles, title_to_id, cutoff)\n",
    "                if mid is not None:\n",
    "                    matched_list.append(mid)\n",
    "                else:\n",
    "                    matched_list.append(title)\n",
    "                    unmatched_titles.append(title)\n",
    "\n",
    "            # keep exactly k=10\n",
    "            matched_list = (matched_list + [None] * 10)[:10]\n",
    "            per_user_recs[uid] = matched_list\n",
    "            all_recs.extend(matched_list)\n",
    "\n",
    "        # === Step 2: Cluster unmatched titles (RapidFuzz ≥ 0.7) ===\n",
    "        title_cluster_map = cluster_unmatched_titles(unmatched_titles, cutoff)\n",
    "        final_recs = [\n",
    "            title_cluster_map.get(x, x) if isinstance(x, str) else x\n",
    "            for x in all_recs\n",
    "        ]\n",
    "\n",
    "        # === Step 3: Exposure counting (includes IDs, clusters, None) ===\n",
    "        exposure_counter = Counter(final_recs)\n",
    "        exposure_counts = list(exposure_counter.values())\n",
    "\n",
    "        # === Step 4: Accuracy metrics (averaged per user) ===\n",
    "        hr_list, prec_list, ndcg_list = [], [], []\n",
    "        for uid, recs in per_user_recs.items():\n",
    "            gt = gt_by_user.get(uid)\n",
    "            if not gt:\n",
    "                continue\n",
    "            gt_ids = set(gt[\"ground_truth_total_itemIds\"]) - {x[0] for x in gt[\"sample_random\"]}\n",
    "            if not gt_ids:\n",
    "                continue\n",
    "\n",
    "            # Order preserved for NDCG\n",
    "            rec_ids_only = [x if isinstance(x, int) else None for x in recs]\n",
    "            hr_list.append(hit_ratio_at_k(rec_ids_only, gt_ids))\n",
    "            prec_list.append(precision_at_k(rec_ids_only, gt_ids))\n",
    "            ndcg_list.append(ndcg_at_k(rec_ids_only, gt_ids))\n",
    "\n",
    "        # === Step 5: Aggregate results ===\n",
    "        metrics_rows.append({\n",
    "            \"style\": style,\n",
    "            \"template_set\": template,\n",
    "            \"HR@10\": round(np.mean(hr_list), 4),\n",
    "            \"Precision@10\": round(np.mean(prec_list), 4),\n",
    "            \"NDCG@10\": round(np.mean(ndcg_list), 4),\n",
    "            \"Gini\": gini_index(exposure_counts),\n",
    "            \"Entropy\": natural_entropy(exposure_counts),\n",
    "            \"num_unique_exposed_titles\": len(exposure_counter),\n",
    "            \"num_exposure_events\": sum(exposure_counts)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_rows)\n",
    "\n",
    "# Run evaluation\n",
    "df_metrics = evaluate_all_metrics(\n",
    "    df_greedy_recs=df_replaced,\n",
    "    df_movies=df_movies,\n",
    "    df_filtered_user_data=df_filtered_user_data,\n",
    "    cutoff=0.8   # RapidFuzz similarity threshold\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "870eaf57a0804d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:11:24.552357Z",
     "start_time": "2025-10-19T01:11:24.543324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>template_set</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>Gini</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>num_unique_exposed_titles</th>\n",
       "      <th>num_exposure_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>few_shot</td>\n",
       "      <td>A</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>4.2582</td>\n",
       "      <td>165</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>few_shot</td>\n",
       "      <td>B</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>4.3755</td>\n",
       "      <td>177</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>few_shot</td>\n",
       "      <td>C</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>4.3032</td>\n",
       "      <td>163</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>A</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>4.1581</td>\n",
       "      <td>147</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>B</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.3433</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>4.1720</td>\n",
       "      <td>153</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>C</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>4.2982</td>\n",
       "      <td>161</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>A</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>2.6442</td>\n",
       "      <td>25</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>B</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>3.2703</td>\n",
       "      <td>77</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>C</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>3.7325</td>\n",
       "      <td>107</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>A</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>2.5660</td>\n",
       "      <td>25</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>B</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>3.6546</td>\n",
       "      <td>93</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>C</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>3.6980</td>\n",
       "      <td>104</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            style template_set  HR@10  Precision@10  NDCG@10    Gini  Entropy  \\\n",
       "0        few_shot            A   0.93         0.297   0.3304  0.6579   4.2582   \n",
       "1        few_shot            B   0.91         0.317   0.3505  0.6389   4.3755   \n",
       "2        few_shot            C   0.95         0.318   0.3491  0.6400   4.3032   \n",
       "3    few_shot_cot            A   0.94         0.311   0.3399  0.6587   4.1581   \n",
       "4    few_shot_cot            B   0.93         0.314   0.3433  0.6629   4.1720   \n",
       "5    few_shot_cot            C   0.98         0.334   0.3649  0.6401   4.2982   \n",
       "6       zero_shot            A   0.96         0.312   0.3784  0.5332   2.6442   \n",
       "7       zero_shot            B   0.89         0.292   0.3052  0.7346   3.2703   \n",
       "8       zero_shot            C   0.83         0.283   0.2989  0.6960   3.7325   \n",
       "9   zero_shot_cot            A   0.96         0.310   0.3645  0.5530   2.5660   \n",
       "10  zero_shot_cot            B   0.89         0.264   0.2893  0.6827   3.6546   \n",
       "11  zero_shot_cot            C   0.74         0.192   0.2209  0.6982   3.6980   \n",
       "\n",
       "    num_unique_exposed_titles  num_exposure_events  \n",
       "0                         165                 1000  \n",
       "1                         177                 1000  \n",
       "2                         163                 1000  \n",
       "3                         147                 1000  \n",
       "4                         153                 1000  \n",
       "5                         161                 1000  \n",
       "6                          25                 1000  \n",
       "7                          77                 1000  \n",
       "8                         107                 1000  \n",
       "9                          25                 1000  \n",
       "10                         93                 1000  \n",
       "11                        104                 1000  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b12d901681c72785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:12:10.635404Z",
     "start_time": "2025-10-19T01:12:10.630415Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics.to_csv(\"results_templates/template_gpt_4o_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "da5465873124681e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:35:49.562394Z",
     "start_time": "2025-10-25T00:35:48.796980Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ====== Config ======\n",
    "files = {\n",
    "    \"results_templates/template_gpt_4o.csv\": \"gpt-4o\",\n",
    "    \"results_templates/template_gpt_4o_mini.csv\": \"gpt-4o-mini\",\n",
    "    # \"results_templates/template_gpt_4.1_mini.csv\": \"gpt-4.1-mini\",\n",
    "    # \"results_templates/template_gpt_4.1_nano.csv\": \"gpt-4.1-nano\",\n",
    "    \"results_templates/template_mistral.csv\": \"mistral-large-2\",\n",
    "    \"results_templates/template_mistral-7.csv\": \"mistral-7B\",\n",
    "}\n",
    "\n",
    "# All metrics available\n",
    "metrics = [\"HR@10\", \"Precision@10\", \"NDCG@10\", \"Gini\", \"Entropy\"]\n",
    "\n",
    "# Only these will be used to compute the average rank\n",
    "metrics_for_avg = [\"NDCG@10\", \"Gini\", \"Entropy\"]\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "# ====== Step 1: Load and rank ======\n",
    "for path, model in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"model\"] = model\n",
    "\n",
    "    # Rank templates *within each style* (A vs B vs C)\n",
    "    for metric in metrics:\n",
    "        if metric == \"Gini\":  # lower is better\n",
    "            df[f\"{metric}_rank\"] = df.groupby(\"style\")[metric].rank(ascending=True, method=\"dense\")\n",
    "        else:  # higher is better\n",
    "            df[f\"{metric}_rank\"] = df.groupby(\"style\")[metric].rank(ascending=False, method=\"dense\")\n",
    "\n",
    "    # Average rank only for NDCG, Gini, and Entropy\n",
    "    rank_cols_for_avg = [f\"{m}_rank\" for m in metrics_for_avg]\n",
    "    df[\"avg_rank\"] = df[rank_cols_for_avg].mean(axis=1)\n",
    "\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Combine all models’ results\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# ====== Step 2: Aggregate per (model, style, template_set) ======\n",
    "per_model = (\n",
    "    combined_df\n",
    "    .groupby([\"model\", \"style\", \"template_set\"])\n",
    "    .agg(\n",
    "        {**{m: \"mean\" for m in metrics},                # average metric values\n",
    "         **{f\"{m}_rank\": \"mean\" for m in metrics},      # average metric ranks\n",
    "         \"avg_rank\": \"mean\"}                            # average of NDCG+Gini+Entropy ranks\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"model\", \"style\", \"avg_rank\"])\n",
    ")\n",
    "\n",
    "# ====== Step 3: Add best_template flag per (model, style) ======\n",
    "per_model[\"best_template\"] = per_model.groupby([\"model\", \"style\"])[\"avg_rank\"].transform(lambda x: x == x.min())\n",
    "\n",
    "# ====== Step 4: Save ======\n",
    "per_model.to_csv(\"per_model_template_ranking.csv\", index=False)\n",
    "\n",
    "print(\"Done. Files saved:\")\n",
    "print(\"Per-model rankings → per_model_template_ranking.csv\")\n",
    "\n",
    "print(\"\\nExample per-model view:\")\n",
    "print(per_model.head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Files saved:\n",
      "Per-model rankings → per_model_template_ranking.csv\n",
      "\n",
      "Example per-model view:\n",
      "     model          style template_set  HR@10  Precision@10  NDCG@10    Gini  \\\n",
      "2   gpt-4o       few_shot            C   0.99         0.584   0.6181  0.5500   \n",
      "1   gpt-4o       few_shot            B   1.00         0.605   0.6378  0.5791   \n",
      "0   gpt-4o       few_shot            A   1.00         0.638   0.6612  0.6207   \n",
      "5   gpt-4o   few_shot_cot            C   0.99         0.551   0.5796  0.5657   \n",
      "4   gpt-4o   few_shot_cot            B   1.00         0.607   0.6342  0.5958   \n",
      "3   gpt-4o   few_shot_cot            A   1.00         0.625   0.6533  0.6249   \n",
      "8   gpt-4o      zero_shot            C   0.98         0.398   0.4177  0.7068   \n",
      "6   gpt-4o      zero_shot            A   0.95         0.303   0.3527  0.5392   \n",
      "7   gpt-4o      zero_shot            B   0.97         0.396   0.4068  0.7150   \n",
      "11  gpt-4o  zero_shot_cot            C   0.97         0.408   0.4139  0.6615   \n",
      "\n",
      "    Entropy  HR@10_rank  Precision@10_rank  NDCG@10_rank  Gini_rank  \\\n",
      "2    4.9182         2.0                3.0           3.0        1.0   \n",
      "1    4.7995         1.0                2.0           2.0        2.0   \n",
      "0    4.5156         1.0                1.0           1.0        3.0   \n",
      "5    4.8871         2.0                3.0           3.0        1.0   \n",
      "4    4.6948         1.0                2.0           2.0        2.0   \n",
      "3    4.4671         1.0                1.0           1.0        3.0   \n",
      "8    3.6794         1.0                1.0           1.0        2.0   \n",
      "6    2.5592         3.0                3.0           3.0        1.0   \n",
      "7    3.5792         2.0                2.0           2.0        3.0   \n",
      "11   3.9990         1.0                2.0           2.0        2.0   \n",
      "\n",
      "    Entropy_rank  avg_rank  best_template  \n",
      "2            1.0  1.666667           True  \n",
      "1            2.0  2.000000          False  \n",
      "0            3.0  2.333333          False  \n",
      "5            1.0  1.666667           True  \n",
      "4            2.0  2.000000          False  \n",
      "3            3.0  2.333333          False  \n",
      "8            1.0  1.333333           True  \n",
      "6            3.0  2.333333          False  \n",
      "7            2.0  2.333333          False  \n",
      "11           1.0  1.666667           True  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "8e786ea321dd8d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:35:53.463890Z",
     "start_time": "2025-10-25T00:35:53.382998Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the categorical order A, B, C\n",
    "template_order = pd.CategoricalDtype(categories=['A', 'B', 'C'], ordered=True)\n",
    "per_model['template_set'] = per_model['template_set'].astype(template_order)\n",
    "\n",
    "# === Mean & Std (plus count) for avg_rank by template ===\n",
    "template_stats = (\n",
    "    per_model.groupby('template_set', observed=True)['NDCG@10_rank']\n",
    "      .agg(mean='mean', std='std', n='size')\n",
    "      .sort_index()  # respects A, B, C\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "print(template_stats.round(4))\n",
    "\n",
    "# If you want just mean & std in a compact table:\n",
    "mean_std_only = template_stats[['mean', 'std']].round(4)\n",
    "print(mean_std_only)\n",
    "\n",
    "# If you prefer to sort by \"best\" (lowest mean avg_rank):\n",
    "template_stats.sort_values('mean').round(4)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean     std   n\n",
      "template_set                    \n",
      "A             2.0000  0.9661  16\n",
      "B             1.9375  0.6801  16\n",
      "C             2.0625  0.8539  16\n",
      "                mean     std\n",
      "template_set                \n",
      "A             2.0000  0.9661\n",
      "B             1.9375  0.6801\n",
      "C             2.0625  0.8539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                mean     std   n\n",
       "template_set                    \n",
       "B             1.9375  0.6801  16\n",
       "A             2.0000  0.9661  16\n",
       "C             2.0625  0.8539  16"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>template_set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.9375</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>2.0625</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "e9d5125a4fca7877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:36:09.291308Z",
     "start_time": "2025-10-25T00:36:09.256068Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the categorical order A, B, C\n",
    "template_order = pd.CategoricalDtype(categories=['A', 'B', 'C'], ordered=True)\n",
    "per_model['template_set'] = per_model['template_set'].astype(template_order)\n",
    "\n",
    "# === Mean & Std (plus count) for avg_rank by template ===\n",
    "template_stats = (\n",
    "    per_model.groupby('template_set', observed=True)['Entropy_rank']\n",
    "      .agg(mean='mean', std='std', n='size')\n",
    "      .sort_index()  # respects A, B, C\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "print(template_stats.round(4))\n",
    "\n",
    "# If you want just mean & std in a compact table:\n",
    "mean_std_only = template_stats[['mean', 'std']].round(4)\n",
    "print(mean_std_only)\n",
    "\n",
    "# If you prefer to sort by \"best\" (lowest mean avg_rank):\n",
    "template_stats.sort_values('mean').round(4)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean     std   n\n",
      "template_set                    \n",
      "A             2.6250  0.7188  16\n",
      "B             2.0625  0.4425  16\n",
      "C             1.3125  0.7042  16\n",
      "                mean     std\n",
      "template_set                \n",
      "A             2.6250  0.7188\n",
      "B             2.0625  0.4425\n",
      "C             1.3125  0.7042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                mean     std   n\n",
       "template_set                    \n",
       "C             1.3125  0.7042  16\n",
       "B             2.0625  0.4425  16\n",
       "A             2.6250  0.7188  16"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>template_set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.3125</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2.0625</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2.6250</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "4db9636577cd7131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:50:54.453920Z",
     "start_time": "2025-10-25T00:50:54.446978Z"
    }
   },
   "source": [
    "results=per_model"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "edefb7fcd7592e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:50:56.258804Z",
     "start_time": "2025-10-25T00:50:56.148739Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure correct template order\n",
    "template_order = pd.CategoricalDtype(categories=['A', 'B', 'C'], ordered=True)\n",
    "results['template_set'] = results['template_set'].astype(template_order)\n",
    "\n",
    "# === Step 1 – Compute mean & std of rank metrics per (model, template) ===\n",
    "rank_metrics = ['Gini_rank', 'Entropy_rank', 'NDCG@10_rank']\n",
    "summary = (\n",
    "    results.groupby(['model', 'template_set'], observed=True)[rank_metrics]\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten multi-index column names\n",
    "summary.columns = ['model', 'template_set'] + [f\"{m}_{s}\" for m, s in summary.columns[2:]]\n",
    "\n",
    "# === Step 2 – Hierarchical ranking by (mean, std) for each metric ===\n",
    "def rank_with_tiebreak(df, mean_col, std_col):\n",
    "    # Sort primarily by mean, then by std (both ascending)\n",
    "    df = df.sort_values([mean_col, std_col], ascending=[True, True]).copy()\n",
    "    # Assign rank with average for ties (e.g., 1, 1, 3)\n",
    "    ranks = df[[mean_col, std_col]].apply(tuple, axis=1).rank(method='dense')\n",
    "    return ranks\n",
    "\n",
    "summary['Gini_mean_rank'] = summary.groupby('model', group_keys=False).apply(\n",
    "    lambda g: rank_with_tiebreak(g, 'Gini_rank_mean', 'Gini_rank_std')\n",
    ")\n",
    "\n",
    "summary['Entropy_mean_rank'] = summary.groupby('model', group_keys=False).apply(\n",
    "    lambda g: rank_with_tiebreak(g, 'Entropy_rank_mean', 'Entropy_rank_std')\n",
    ")\n",
    "\n",
    "summary['NDCG_mean_rank'] = summary.groupby('model', group_keys=False).apply(\n",
    "    lambda g: rank_with_tiebreak(g, 'NDCG@10_rank_mean', 'NDCG@10_rank_std')\n",
    ")\n",
    "\n",
    "# === Step 3 – Compute average rank across metrics ===\n",
    "rank_cols = ['Gini_mean_rank', 'Entropy_mean_rank', 'NDCG_mean_rank']\n",
    "summary['avg_rank'] = summary[rank_cols].mean(axis=1)\n",
    "summary['avg_rank_std'] = summary[rank_cols].std(axis=1)\n",
    "\n",
    "# === Step 4 – Sort & identify best template per model ===\n",
    "summary = summary.sort_values(['model', 'avg_rank'])\n",
    "best_templates = summary.groupby('model', as_index=False).first()\n",
    "\n",
    "# === Step 5 – Display ===\n",
    "print(\"\\n=== Template-level Mean / Std and Ranks for Each Model ===\")\n",
    "print(summary[['model', 'template_set',\n",
    "               'Gini_rank_mean', 'Gini_rank_std', 'Gini_mean_rank',\n",
    "               'Entropy_rank_mean', 'Entropy_rank_std', 'Entropy_mean_rank',\n",
    "               'NDCG@10_rank_mean', 'NDCG@10_rank_std', 'NDCG_mean_rank',\n",
    "               'avg_rank', 'avg_rank_std']].round(4))\n",
    "\n",
    "print(\"\\n=== Best Template per Model (lowest avg rank) ===\")\n",
    "print(best_templates[['model', 'template_set', 'avg_rank']].round(4))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Template-level Mean / Std and Ranks for Each Model ===\n",
      "              model template_set  Gini_rank_mean  Gini_rank_std  \\\n",
      "2            gpt-4o            C            1.50         0.5774   \n",
      "1            gpt-4o            B            2.50         0.5774   \n",
      "0            gpt-4o            A            2.00         1.1547   \n",
      "3       gpt-4o-mini            A            1.75         0.9574   \n",
      "4       gpt-4o-mini            B            2.25         0.9574   \n",
      "5       gpt-4o-mini            C            2.00         0.8165   \n",
      "6        mistral-7B            A            1.25         0.5000   \n",
      "8        mistral-7B            C            3.00         0.0000   \n",
      "7        mistral-7B            B            1.75         0.5000   \n",
      "11  mistral-large-2            C            2.00         0.8165   \n",
      "10  mistral-large-2            B            2.00         0.8165   \n",
      "9   mistral-large-2            A            2.00         1.1547   \n",
      "\n",
      "    Gini_mean_rank  Entropy_rank_mean  Entropy_rank_std  Entropy_mean_rank  \\\n",
      "2              1.0               1.00            0.0000                1.0   \n",
      "1              3.0               2.00            0.0000                2.0   \n",
      "0              2.0               3.00            0.0000                3.0   \n",
      "3              1.0               3.00            0.0000                3.0   \n",
      "4              3.0               1.75            0.5000                2.0   \n",
      "5              2.0               1.25            0.5000                1.0   \n",
      "6              1.0               1.50            0.5774                1.0   \n",
      "8              3.0               2.00            1.1547                2.0   \n",
      "7              2.0               2.50            0.5774                3.0   \n",
      "11             1.0               1.00            0.0000                1.0   \n",
      "10             1.0               2.00            0.0000                2.0   \n",
      "9              2.0               3.00            0.0000                3.0   \n",
      "\n",
      "    NDCG@10_rank_mean  NDCG@10_rank_std  NDCG_mean_rank  avg_rank  \\\n",
      "2                2.25            0.9574             3.0    1.6667   \n",
      "1                1.75            0.5000             1.0    2.0000   \n",
      "0                2.00            1.1547             2.0    2.3333   \n",
      "3                2.00            1.1547             2.0    2.0000   \n",
      "4                1.75            0.5000             1.0    2.0000   \n",
      "5                2.25            0.9574             3.0    2.0000   \n",
      "6                1.50            0.5774             1.0    1.0000   \n",
      "8                2.00            1.1547             2.0    2.3333   \n",
      "7                2.50            0.5774             3.0    2.6667   \n",
      "11               1.75            0.5000             1.0    1.0000   \n",
      "10               1.75            0.9574             2.0    1.6667   \n",
      "9                2.50            1.0000             3.0    2.6667   \n",
      "\n",
      "    avg_rank_std  \n",
      "2         1.1547  \n",
      "1         1.0000  \n",
      "0         0.5774  \n",
      "3         1.0000  \n",
      "4         1.0000  \n",
      "5         1.0000  \n",
      "6         0.0000  \n",
      "8         0.5774  \n",
      "7         0.5774  \n",
      "11        0.0000  \n",
      "10        0.5774  \n",
      "9         0.5774  \n",
      "\n",
      "=== Best Template per Model (lowest avg rank) ===\n",
      "             model template_set  avg_rank\n",
      "0           gpt-4o            C    1.6667\n",
      "1      gpt-4o-mini            A    2.0000\n",
      "2       mistral-7B            A    1.0000\n",
      "3  mistral-large-2            C    1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S4148069\\AppData\\Local\\Temp\\ipykernel_27656\\3361552339.py:27: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary['Gini_mean_rank'] = summary.groupby('model', group_keys=False).apply(\n",
      "C:\\Users\\S4148069\\AppData\\Local\\Temp\\ipykernel_27656\\3361552339.py:31: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary['Entropy_mean_rank'] = summary.groupby('model', group_keys=False).apply(\n",
      "C:\\Users\\S4148069\\AppData\\Local\\Temp\\ipykernel_27656\\3361552339.py:35: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary['NDCG_mean_rank'] = summary.groupby('model', group_keys=False).apply(\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "b64b47e5f4a9848e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:51:01.413375Z",
     "start_time": "2025-10-25T00:51:01.402525Z"
    }
   },
   "source": [
    "summary.to_csv(\"per_model_template_reranking_based_on_average_rank.csv\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "e6e23429204380a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:51:04.803696Z",
     "start_time": "2025-10-25T00:51:04.762520Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure correct template order\n",
    "template_order = pd.CategoricalDtype(categories=['A', 'B', 'C'], ordered=True)\n",
    "results['template_set'] = results['template_set'].astype(template_order)\n",
    "\n",
    "# === Step 1 – Compute mean & std of rank metrics per (model, template) ===\n",
    "rank_metrics = ['Gini_rank', 'Entropy_rank', 'NDCG@10_rank']#,'Precision@10_rank']\n",
    "\n",
    "summary = (\n",
    "    results.groupby(['style', 'template_set'], observed=True)[rank_metrics]\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten multi-index column names\n",
    "summary.columns = ['style', 'template_set'] + [f\"{m}_{s}\" for m, s in summary.columns[2:]]\n",
    "\n",
    "# === Step 2 – Within each model, rank templates for each metric (by mean) ===\n",
    "summary['Gini_mean_rank'] = summary.groupby('style')['Gini_rank_mean'].rank(method='dense', ascending=True)\n",
    "summary['Entropy_mean_rank'] = summary.groupby('style')['Entropy_rank_mean'].rank(method='dense', ascending=True)\n",
    "summary['NDCG_mean_rank'] = summary.groupby('style')['NDCG@10_rank_mean'].rank(method='dense', ascending=True)\n",
    "#summary['Precision_mean_rank'] = summary.groupby('style')['Precision@10_rank_mean'].rank(method='average', ascending=True)\n",
    "\n",
    "# === Step 3 – Compute average & std of these three ranks ===\n",
    "rank_cols = ['Gini_mean_rank', 'Entropy_mean_rank', 'NDCG_mean_rank']#'Precision_mean_rank']\n",
    "summary['avg_rank'] = summary[rank_cols].mean(axis=1)\n",
    "summary['avg_rank_std'] = summary[rank_cols].std(axis=1)\n",
    "\n",
    "# === Step 4 – Sort & identify best template per model (lowest avg rank) ===\n",
    "summary = summary.sort_values(['style', 'avg_rank'])\n",
    "best_templates = summary.groupby('style', as_index=False).first()\n",
    "\n",
    "# === Step 5 – Display results ===\n",
    "print(\"\\n=== Template-level Mean / Std and Ranks for Each style ===\")\n",
    "print(summary[['style', 'template_set',\n",
    "               'Gini_rank_mean', 'Gini_rank_std', 'Gini_mean_rank',\n",
    "               'Entropy_rank_mean', 'Entropy_rank_std', 'Entropy_mean_rank',\n",
    "               'NDCG@10_rank_mean', 'NDCG@10_rank_std', 'NDCG_mean_rank',\n",
    "              #  'Precision@10_rank_mean', 'Precision@10_rank_std', 'Precision_mean_rank',\n",
    "               'avg_rank', 'avg_rank_std']].round(4))\n",
    "\n",
    "print(\"\\n=== Best Template per Model (lowest avg rank) ===\")\n",
    "print(best_templates[['style', 'template_set', 'avg_rank']].round(4))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Template-level Mean / Std and Ranks for Each style ===\n",
      "            style template_set  Gini_rank_mean  Gini_rank_std  Gini_mean_rank  \\\n",
      "1        few_shot            B            1.25         0.5000             1.0   \n",
      "0        few_shot            A            2.75         0.5000             3.0   \n",
      "2        few_shot            C            2.00         0.8165             2.0   \n",
      "4    few_shot_cot            B            2.25         0.5000             2.0   \n",
      "5    few_shot_cot            C            1.50         1.0000             1.0   \n",
      "3    few_shot_cot            A            2.25         0.9574             2.0   \n",
      "8       zero_shot            C            2.50         0.5774             2.0   \n",
      "6       zero_shot            A            1.00         0.0000             1.0   \n",
      "7       zero_shot            B            2.50         0.5774             2.0   \n",
      "10  zero_shot_cot            B            2.50         0.5774             2.0   \n",
      "11  zero_shot_cot            C            2.50         0.5774             2.0   \n",
      "9   zero_shot_cot            A            1.00         0.0000             1.0   \n",
      "\n",
      "    Entropy_rank_mean  Entropy_rank_std  Entropy_mean_rank  NDCG@10_rank_mean  \\\n",
      "1                1.75            0.5000                1.0               2.00   \n",
      "0                2.50            1.0000                2.0               1.50   \n",
      "2                1.75            0.9574                1.0               2.50   \n",
      "4                2.00            0.0000                2.0               1.75   \n",
      "5                1.50            1.0000                1.0               2.25   \n",
      "3                2.50            1.0000                3.0               2.00   \n",
      "8                1.00            0.0000                1.0               1.50   \n",
      "6                2.75            0.5000                3.0               2.25   \n",
      "7                2.25            0.5000                2.0               2.25   \n",
      "10               2.25            0.5000                2.0               1.75   \n",
      "11               1.00            0.0000                1.0               2.00   \n",
      "9                2.75            0.5000                3.0               2.25   \n",
      "\n",
      "    NDCG@10_rank_std  NDCG_mean_rank  avg_rank  avg_rank_std  \n",
      "1             0.8165             2.0    1.3333        0.5774  \n",
      "0             1.0000             1.0    2.0000        1.0000  \n",
      "2             0.5774             3.0    2.0000        1.0000  \n",
      "4             0.5000             1.0    1.6667        0.5774  \n",
      "5             0.9574             3.0    1.6667        1.1547  \n",
      "3             1.1547             2.0    2.3333        0.5774  \n",
      "8             1.0000             1.0    1.3333        0.5774  \n",
      "6             0.9574             2.0    2.0000        1.0000  \n",
      "7             0.5000             2.0    2.0000        0.0000  \n",
      "10            0.9574             1.0    1.6667        0.5774  \n",
      "11            0.8165             2.0    1.6667        0.5774  \n",
      "9             0.9574             3.0    2.3333        1.1547  \n",
      "\n",
      "=== Best Template per Model (lowest avg rank) ===\n",
      "           style template_set  avg_rank\n",
      "0       few_shot            B    1.3333\n",
      "1   few_shot_cot            B    1.6667\n",
      "2      zero_shot            C    1.3333\n",
      "3  zero_shot_cot            B    1.6667\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "ba16b2755a16384f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:51:08.836283Z",
     "start_time": "2025-10-25T00:51:08.813313Z"
    }
   },
   "source": [
    "summary.head(20)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            style template_set  Gini_rank_mean  Gini_rank_std  \\\n",
       "1        few_shot            B            1.25       0.500000   \n",
       "0        few_shot            A            2.75       0.500000   \n",
       "2        few_shot            C            2.00       0.816497   \n",
       "4    few_shot_cot            B            2.25       0.500000   \n",
       "5    few_shot_cot            C            1.50       1.000000   \n",
       "3    few_shot_cot            A            2.25       0.957427   \n",
       "8       zero_shot            C            2.50       0.577350   \n",
       "6       zero_shot            A            1.00       0.000000   \n",
       "7       zero_shot            B            2.50       0.577350   \n",
       "10  zero_shot_cot            B            2.50       0.577350   \n",
       "11  zero_shot_cot            C            2.50       0.577350   \n",
       "9   zero_shot_cot            A            1.00       0.000000   \n",
       "\n",
       "    Entropy_rank_mean  Entropy_rank_std  NDCG@10_rank_mean  NDCG@10_rank_std  \\\n",
       "1                1.75          0.500000               2.00          0.816497   \n",
       "0                2.50          1.000000               1.50          1.000000   \n",
       "2                1.75          0.957427               2.50          0.577350   \n",
       "4                2.00          0.000000               1.75          0.500000   \n",
       "5                1.50          1.000000               2.25          0.957427   \n",
       "3                2.50          1.000000               2.00          1.154701   \n",
       "8                1.00          0.000000               1.50          1.000000   \n",
       "6                2.75          0.500000               2.25          0.957427   \n",
       "7                2.25          0.500000               2.25          0.500000   \n",
       "10               2.25          0.500000               1.75          0.957427   \n",
       "11               1.00          0.000000               2.00          0.816497   \n",
       "9                2.75          0.500000               2.25          0.957427   \n",
       "\n",
       "    Gini_mean_rank  Entropy_mean_rank  NDCG_mean_rank  avg_rank  avg_rank_std  \n",
       "1              1.0                1.0             2.0  1.333333      0.577350  \n",
       "0              3.0                2.0             1.0  2.000000      1.000000  \n",
       "2              2.0                1.0             3.0  2.000000      1.000000  \n",
       "4              2.0                2.0             1.0  1.666667      0.577350  \n",
       "5              1.0                1.0             3.0  1.666667      1.154701  \n",
       "3              2.0                3.0             2.0  2.333333      0.577350  \n",
       "8              2.0                1.0             1.0  1.333333      0.577350  \n",
       "6              1.0                3.0             2.0  2.000000      1.000000  \n",
       "7              2.0                2.0             2.0  2.000000      0.000000  \n",
       "10             2.0                2.0             1.0  1.666667      0.577350  \n",
       "11             2.0                1.0             2.0  1.666667      0.577350  \n",
       "9              1.0                3.0             3.0  2.333333      1.154701  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>template_set</th>\n",
       "      <th>Gini_rank_mean</th>\n",
       "      <th>Gini_rank_std</th>\n",
       "      <th>Entropy_rank_mean</th>\n",
       "      <th>Entropy_rank_std</th>\n",
       "      <th>NDCG@10_rank_mean</th>\n",
       "      <th>NDCG@10_rank_std</th>\n",
       "      <th>Gini_mean_rank</th>\n",
       "      <th>Entropy_mean_rank</th>\n",
       "      <th>NDCG_mean_rank</th>\n",
       "      <th>avg_rank</th>\n",
       "      <th>avg_rank_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>few_shot</td>\n",
       "      <td>B</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>few_shot</td>\n",
       "      <td>A</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>few_shot</td>\n",
       "      <td>C</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>B</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>C</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.154701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>few_shot_cot</td>\n",
       "      <td>A</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>C</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>A</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zero_shot</td>\n",
       "      <td>B</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>B</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>C</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zero_shot_cot</td>\n",
       "      <td>A</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.154701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "a3b51ea6814dc456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T00:51:11.487379Z",
     "start_time": "2025-10-25T00:51:11.476143Z"
    }
   },
   "source": [
    "summary.to_csv(\"per_style_template_reranking_based_on_average_rank.csv\")"
   ],
   "outputs": [],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
